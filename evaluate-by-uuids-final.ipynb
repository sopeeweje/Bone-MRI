{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline  \n",
    "from IPython.display import display, HTML, SVG\n",
    "from db import Result\n",
    "import papermill as pm\n",
    "import os\n",
    "import seaborn\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict \n",
    "from sklearn.metrics import auc, precision_recall_curve, roc_curve, confusion_matrix, roc_auc_score, roc_curve, f1_score, accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from evaluate import calculate_confusion_matrix_stats_predictions, calculate_roc_curve, roc_auc_score\n",
    "from scipy.stats import binom_test, fisher_exact, chi2_contingency\n",
    "from tabulate import tabulate\n",
    "from calculate_features import all_features\n",
    "from config import config\n",
    "from data import data\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP = False\n",
    "UUIDS = [    \n",
    "#    \"7bd2f246-f096-4dfb-86ba-2abb4fa37d4d\", # features\n",
    "#    \"31e84705-3483-406d-9699-026d3367f31f\", # t2\n",
    "#    \"b776df8a-f966-4afd-bf7a-f2b4c1fe3a1c\", # t1\n",
    "#    \"01e93f79-3d49-4809-8dab-fa2055724377\", # backup t1\n",
    "#    \"5d1d4156-ee5a-49ff-87cf-ad4a11be8aef\", # t1\n",
    "#    \"47cf8213-5aca-4e1f-b2ba-8dbf4aac7830\", # t2\n",
    "#    \"b0fb56eb-f2fa-4a5a-bd76-297ec64a371e\", # features\n",
    "#    \"02aa461f-be56-4138-9fcd-084a56bab732\", # t2\n",
    "#    \"cdbba6a0-73b3-4ef8-8ea5-1a5f64525320\", # t2    \n",
    "#     \"405a845e-febd-4a81-a864-72d10f45c757\", # t2 overfit\n",
    "#     \"95b693b8-6ab8-4862-ae6a-404d33751327\", # t1 nice sensitivity and specificity balance\n",
    "#     \"d2ccc80f-35f2-4477-943e-708e48c518a4\", # t1 not great 0.66 validation acc\n",
    "#     \"79e0e7d4-4250-4935-abfa-c4bbccc19748\", # t2 not great 0.66 validation acc but works with ^ with less correlation\n",
    "#     \"40b2f9eb-44cc-4fef-9580-e560ceac8315\", # t1 overfit\n",
    "#     \"75683443-233d-4f78-ae9f-f7c6ed085611\", # t1, \n",
    "#     \"a063f816-ae0e-42ab-92aa-f00092cec894\", # features    \n",
    "\n",
    "#     \"59a36cd3-40b9-479f-9764-b7d8223264f7\", # t2\n",
    "#     \"ab1a810d-5a82-434d-8ecd-28459d7dd137\", # t1\n",
    "     \"ebe1e4e9-fd1a-44c5-b06a-6c77579b5be5\", # features\n",
    "#    \"c798ed37-3dbc-4515-9559-f2d04d42d679\", # t2 by auc\n",
    "#     \"1140a993-9934-45ee-b354-c3c778a4ff61\", # t1 by validation specificity\n",
    "#     \"bbcee945-5abb-4d11-8035-68b8a3d484d4\", # t2 by validation sensitivity\n",
    "#     \"bcae9141-60d6-4e54-b4d6-af01549681bb\", # t2 by validation specificity\n",
    "#     \"86e91ce1-e2ba-4726-bfad-e68ea926e0f7\", # t1 by validation sensitivity\n",
    "     \"59a36cd3-40b9-479f-9764-b7d8223264f7\", # t2\n",
    "     \"acdd5165-089b-48fd-a936-af404577f7cf\", # t1\n",
    "]\n",
    "SELECTIONS = {\n",
    "    # old selections\n",
    "    \"9adb8e80-457c-4419-8b01-92325ba99fc3\": { # t1\n",
    "        (\"benign\", \"benign\"): [\"Kidney-Mayo-060\"],\n",
    "        (\"benign\", \"malignant\"): [\"Kidney-HP-049\"],\n",
    "        (\"malignant\", \"malignant\"): [\"Kidney-Penn-082\"],\n",
    "        (\"malignant\", \"benign\"): [],\n",
    "    },\n",
    "    \"391b0942-7801-4184-b551-2b62fe269c58\": { # t2\n",
    "        (\"benign\", \"benign\"): [\"Kidney-Mayo-055\", \"Kidney-Mayo-054\"],\n",
    "        (\"benign\", \"malignant\"): [\"Kidney-Mayo-046\", \"Kidney-Penn-004\"],\n",
    "        (\"malignant\", \"malignant\"): [\"Kidney-TCGA-034\", \"Kidney-Penn-108\"],\n",
    "        (\"malignant\", \"benign\"): [\"Kidney-Penn-193\", \"Kidney-XY2-007\"],\n",
    "    },\n",
    "}\n",
    "TSNE_PERPLEXITY = {\n",
    "    \"acdd5165-089b-48fd-a936-af404577f7cf\": 10, # t1\n",
    "    \"1140a993-9934-45ee-b354-c3c778a4ff61\": 10, # t1 by validation specificity\n",
    "    \"bbcee945-5abb-4d11-8035-68b8a3d484d4\": 10, # t2 by validation sensitivity\n",
    "    \"bcae9141-60d6-4e54-b4d6-af01549681bb\": 10, # t2 by validation specificity\n",
    "    \"86e91ce1-e2ba-4726-bfad-e68ea926e0f7\": 10, # t1 by validation sensitivity    \n",
    "    \"bbcee945-5abb-4d11-8035-68b8a3d484d4\": 10, # t2 by validation sensitivity    \"\"\n",
    "    \"1140a993-9934-45ee-b354-c3c778a4ff61\": 10, # t1 by test specificity\n",
    "    \"59a36cd3-40b9-479f-9764-b7d8223264f7\": 10, # t2\n",
    "    \"ab1a810d-5a82-434d-8ecd-28459d7dd137\": 10, # t1    \n",
    "    \"75683443-233d-4f78-ae9f-f7c6ed085611\": 10, # t1\n",
    "    \"40b2f9eb-44cc-4fef-9580-e560ceac8315\": 10, # t1 overfit\n",
    "    \"d2ccc80f-35f2-4477-943e-708e48c518a4\": 10, # t1 not great 0.66 validation acc\n",
    "    \"79e0e7d4-4250-4935-abfa-c4bbccc19748\": 20, # t2 not great 0.66 validation acc but works with ^ with less correlation\n",
    "    \"405a845e-febd-4a81-a864-72d10f45c757\": 20, # t2    \n",
    "    \"cdbba6a0-73b3-4ef8-8ea5-1a5f64525320\": 20, # t2\n",
    "    \"02aa461f-be56-4138-9fcd-084a56bab732\": 20, # t2\n",
    "    \"95b693b8-6ab8-4862-ae6a-404d33751327\": 10, # t1\n",
    "    \"612a2e47-7f2c-484e-84d1-1f74c5f583d4\": 20, # t2\n",
    "    # old\n",
    "    \"31e84705-3483-406d-9699-026d3367f31f\": 10, # t2\n",
    "    \"b776df8a-f966-4afd-bf7a-f2b4c1fe3a1c\": 20, # t1\n",
    "    # old\n",
    "    \"5d1d4156-ee5a-49ff-87cf-ad4a11be8aef\": 20, # t1\n",
    "    \"47cf8213-5aca-4e1f-b2ba-8dbf4aac7830\": 10, # t2\n",
    "     \"52858e66-1678-434a-92e4-bc18049cc233\": 10, # t2\n",
    "     \"bc5794f0-5f96-4094-aff6-eab3c22b816a\": 20, # t1\n",
    "    \n",
    "}\n",
    "MODALITY = {\n",
    "     \"acdd5165-089b-48fd-a936-af404577f7cf\": \"t1\", # t1\n",
    "     \"59a36cd3-40b9-479f-9764-b7d8223264f7\": \"t2\", # t2    \n",
    "     \"ebe1e4e9-fd1a-44c5-b06a-6c77579b5be5\": \"features\", # features\"\n",
    "}\n",
    "old_modality = {\n",
    "     \"1140a993-9934-45ee-b354-c3c778a4ff61\": \"t1-specific\", # t1 by validation specificity\n",
    "     \"bbcee945-5abb-4d11-8035-68b8a3d484d4\": \"t2-sensitive\", # t2 by validation sensitivity\n",
    "     \"bcae9141-60d6-4e54-b4d6-af01549681bb\": \"t2-specific\", # t2 by validation specificity\n",
    "     \"86e91ce1-e2ba-4726-bfad-e68ea926e0f7\": \"t1-sensitive\", # t1 by validation sensitivity        \n",
    "     \"1140a993-9934-45ee-b354-c3c778a4ff61\": \"t1\", # t1 by test specificity    \n",
    "     \"59a36cd3-40b9-479f-9764-b7d8223264f7\": \"t2\", # t2\n",
    "     \"ab1a810d-5a82-434d-8ecd-28459d7dd137\": \"t1\", # t1   \n",
    "\n",
    "     \"52858e66-1678-434a-92e4-bc18049cc233\": \"t2\", # t2\n",
    "     \"bc5794f0-5f96-4094-aff6-eab3c22b816a\": \"t1\", # t1\n",
    "     \"6a252ffb-a885-4ace-abee-95064928b494\": \"features\", # features    \n",
    "    \"75683443-233d-4f78-ae9f-f7c6ed085611\": \"t1\", \n",
    "    \"40b2f9eb-44cc-4fef-9580-e560ceac8315\": \"t1\", # t1 overfit\n",
    "    \"d2ccc80f-35f2-4477-943e-708e48c518a4\": \"t1\", # t1 not great 0.66 validation acc\n",
    "    \"79e0e7d4-4250-4935-abfa-c4bbccc19748\": \"t2\", # t2 not great 0.66 validation acc but works with ^ with less correlation    \n",
    "    \"405a845e-febd-4a81-a864-72d10f45c757\": \"t2\", # t2        \n",
    "    \"cdbba6a0-73b3-4ef8-8ea5-1a5f64525320\": \"t2\", # t2\n",
    "    \"02aa461f-be56-4138-9fcd-084a56bab732\": \"t2\", # t2\n",
    "    \"95b693b8-6ab8-4862-ae6a-404d33751327\": \"t1\", # t1\n",
    "    \"612a2e47-7f2c-484e-84d1-1f74c5f583d4\": \"t2\", # t2\n",
    "    \"a063f816-ae0e-42ab-92aa-f00092cec894\": \"features\", # features\n",
    "    # old\n",
    "    \"7bd2f246-f096-4dfb-86ba-2abb4fa37d4d\": \"features\",\n",
    "    \"31e84705-3483-406d-9699-026d3367f31f\": \"t2\",\n",
    "    \"b776df8a-f966-4afd-bf7a-f2b4c1fe3a1c\": \"t1\", \n",
    "    # old\n",
    "    \"5d1d4156-ee5a-49ff-87cf-ad4a11be8aef\": \"t1\", # t1\n",
    "    \"47cf8213-5aca-4e1f-b2ba-8dbf4aac7830\": \"t2\", # t2\n",
    "    \"b0fb56eb-f2fa-4a5a-bd76-297ec64a371e\": \"features\", # features    \n",
    "    # old\n",
    "    \"9adb8e80-457c-4419-8b01-92325ba99fc3\": \"t1\", # t1\n",
    "    \"391b0942-7801-4184-b551-2b62fe269c58\": \"t2\", # t2\n",
    "    \"dce56921-62a8-40f3-8cce-73b06d2b049c\": \"features\", # features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def adjusted_wald(p, n, z=1.96):\n",
    "    p_adj = (n * p + (z**2)/2)/(n+z**2)\n",
    "    n_adj = n + z**2\n",
    "    span = z * math.sqrt(p_adj*(1-p_adj)/n_adj)\n",
    "    return max(0, p_adj - span), min(p_adj + span, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_notebook(uuid, selections=None, tsne_perplexity=5, input_form=\"none\", description=\"\"): \n",
    "    name = \"evaluate-{}-{}-{}.ipynb\".format(description, input_form, uuid)\n",
    "    if not SKIP and not os.path.exists(name): \n",
    "        pm.execute_notebook(\n",
    "            \"evaluate-specific-model.ipynb\",\n",
    "            \"evaluate-{}-{}-{}.ipynb\".format(description, input_form, uuid),\n",
    "            parameters = dict(\n",
    "                UUID=uuid,\n",
    "                SELECTIONS=repr(selections),\n",
    "                TSNE_PERPLEXITY=tsne_perplexity,\n",
    "            ),\n",
    "    )\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_notebooks = list()\n",
    "modality_by_notebook = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input Notebook:  evaluate-specific-model.ipynb\n",
      "Output Notebook: evaluate-round-9-t1-acdd5165-089b-48fd-a936-af404577f7cf.ipynb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebe1e4e9-fd1a-44c5-b06a-6c77579b5be5\n",
      "done\n",
      "59a36cd3-40b9-479f-9764-b7d8223264f7\n",
      "done\n",
      "acdd5165-089b-48fd-a936-af404577f7cf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898be35b299f4618a1873f77ebbbf2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=42), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for uuid in UUIDS: \n",
    "    print(uuid)\n",
    "    result = Result.query.filter(Result.uuid == uuid).first()\n",
    "    name = execute_notebook(uuid, SELECTIONS.get(uuid), TSNE_PERPLEXITY.get(uuid), result.input_form, result.description)\n",
    "    completed_notebooks.append(name)\n",
    "    modality_by_notebook[name] = MODALITY[uuid]\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evaluate-round-9-features-ebe1e4e9-fd1a-44c5-b06a-6c77579b5be5.ipynb': 'features',\n",
       " 'evaluate-randomized-1-t2-59a36cd3-40b9-479f-9764-b7d8223264f7.ipynb': 't2',\n",
       " 'evaluate-round-9-t1-acdd5165-089b-48fd-a936-af404577f7cf.ipynb': 't1'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modality_by_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input Notebook:  evaluate-ensemble.ipynb\n",
      "Output Notebook: evaluate-ensemble-ebe1e4e9-fd1a-44c5-b06a-6c77579b5be5-59a36cd3-40b9-479f-9764-b7d8223264f7-acdd5165-089b-48fd-a936-af404577f7cf.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9e4e37e1a24642a30ab60093231591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=27), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not SKIP: \n",
    "    pm.execute_notebook(\n",
    "        \"evaluate-ensemble.ipynb\",\n",
    "        \"evaluate-ensemble-{}.ipynb\".format(\"-\".join(UUIDS)),\n",
    "        parameters = dict(\n",
    "            MODELS=UUIDS,\n",
    "            SCORE=\"accuracy\",\n",
    "        ),\n",
    "    )\n",
    "completed_notebooks.append(\"evaluate-ensemble-{}.ipynb\".format(\"-\".join(UUIDS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_by_notebook[\"evaluate-ensemble-{}.ipynb\".format(\"-\".join(UUIDS))] = \"ensemble\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notebook_output(notebook, name): \n",
    "    return notebook.dataframe[notebook.dataframe.name==name].value.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dict()\n",
    "validation = dict()\n",
    "test = dict()\n",
    "test_1 = dict()\n",
    "test_2 = dict()\n",
    "for notebook in completed_notebooks: \n",
    "    nb = pm.read_notebook(notebook)\n",
    "    train[\"{}-{}\".format(modality_by_notebook[notebook], \"labels\")] = get_notebook_output(nb, \"train_labels\")\n",
    "    train[\"{}-{}\".format(modality_by_notebook[notebook], \"predictions\")] = get_notebook_output(nb, \"train_predictions\")\n",
    "    train[\"{}-{}\".format(modality_by_notebook[notebook], \"probabilities\")] = get_notebook_output(nb, \"train_probabilities\")\n",
    "    validation[\"{}-{}\".format(modality_by_notebook[notebook], \"labels\")] = get_notebook_output(nb, \"validation_labels\")\n",
    "    validation[\"{}-{}\".format(modality_by_notebook[notebook], \"predictions\")] = get_notebook_output(nb, \"validation_predictions\")\n",
    "    validation[\"{}-{}\".format(modality_by_notebook[notebook], \"probabilities\")] = get_notebook_output(nb, \"validation_probabilities\")\n",
    "    test[\"{}-{}\".format(modality_by_notebook[notebook], \"labels\")] = get_notebook_output(nb, \"test_labels\")\n",
    "    test[\"{}-{}\".format(modality_by_notebook[notebook], \"predictions\")] = get_notebook_output(nb, \"test_predictions\")\n",
    "    test[\"{}-{}\".format(modality_by_notebook[notebook], \"probabilities\")] = get_notebook_output(nb, \"test_probabilities\")\n",
    "    test_1[\"{}-{}\".format(modality_by_notebook[notebook], \"labels\")] = get_notebook_output(nb, \"test-1_labels\")\n",
    "    test_1[\"{}-{}\".format(modality_by_notebook[notebook], \"predictions\")] = get_notebook_output(nb, \"test-1_predictions\")\n",
    "    test_1[\"{}-{}\".format(modality_by_notebook[notebook], \"probabilities\")] = get_notebook_output(nb, \"test-1_probabilities\")\n",
    "    test_2[\"{}-{}\".format(modality_by_notebook[notebook], \"labels\")] = get_notebook_output(nb, \"test-2_labels\")\n",
    "    test_2[\"{}-{}\".format(modality_by_notebook[notebook], \"predictions\")] = get_notebook_output(nb, \"test-2_predictions\")\n",
    "    test_2[\"{}-{}\".format(modality_by_notebook[notebook], \"probabilities\")] = get_notebook_output(nb, \"test-2_probabilities\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['features-labels', 'features-predictions', 'features-probabilities', 't2-labels', 't2-predictions', 't2-probabilities', 't1-labels', 't1-predictions', 't1-probabilities', 'ensemble-labels', 'ensemble-predictions', 'ensemble-probabilities'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['evaluate-round-9-features-ebe1e4e9-fd1a-44c5-b06a-6c77579b5be5.ipynb',\n",
       " 'evaluate-randomized-1-t2-59a36cd3-40b9-479f-9764-b7d8223264f7.ipynb',\n",
       " 'evaluate-round-9-t1-acdd5165-089b-48fd-a936-af404577f7cf.ipynb',\n",
       " 'evaluate-ensemble-ebe1e4e9-fd1a-44c5-b06a-6c77579b5be5-59a36cd3-40b9-479f-9764-b7d8223264f7-acdd5165-089b-48fd-a936-af404577f7cf.ipynb',\n",
       " 'evaluate-ensemble-ebe1e4e9-fd1a-44c5-b06a-6c77579b5be5-59a36cd3-40b9-479f-9764-b7d8223264f7-acdd5165-089b-48fd-a936-af404577f7cf.ipynb']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completed_notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/446 [00:00<03:04,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "Exception occurred for: patient    Kidney-Penn-389\n",
      "volume            0.658486\n",
      "outcome             benign\n",
      "age               0.689655\n",
      "sex                      0\n",
      "sort                 train\n",
      "Name: Kidney-Penn-389, dtype: object\n",
      "[Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-Penn-389-T1C-imagingVolume.nrrd'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 279, in generate_from_features\n",
      "    t1_masked = load_image(t1_image_file, t1_seg_file, verbose=verbose)\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 240, in load_image\n",
      "    image, _ = nrrd.read(image_path)\n",
      "  File \"/home/user1/.local/share/virtualenvs/renal-mri-NanAjWL7/lib/python3.6/site-packages/nrrd/reader.py\", line 427, in read\n",
      "    with open(filename, 'rb') as fh:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-Penn-389-T1C-imagingVolume.nrrd'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 6/446 [00:01<01:41,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "Exception occurred for: patient    Kidney-Penn-430\n",
      "volume            0.658462\n",
      "outcome             benign\n",
      "age               0.735632\n",
      "sex                      1\n",
      "sort                 train\n",
      "Name: Kidney-Penn-430, dtype: object\n",
      "[Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-Penn-430-T1C-imagingVolume.nrrd'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 279, in generate_from_features\n",
      "    t1_masked = load_image(t1_image_file, t1_seg_file, verbose=verbose)\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 240, in load_image\n",
      "    image, _ = nrrd.read(image_path)\n",
      "  File \"/home/user1/.local/share/virtualenvs/renal-mri-NanAjWL7/lib/python3.6/site-packages/nrrd/reader.py\", line 427, in read\n",
      "    with open(filename, 'rb') as fh:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-Penn-430-T1C-imagingVolume.nrrd'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 55/446 [00:16<02:01,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "Exception occurred for: patient    Kidney-Penn-415\n",
      "volume            0.658451\n",
      "outcome             benign\n",
      "age               0.770115\n",
      "sex                      1\n",
      "sort                 train\n",
      "Name: Kidney-Penn-415, dtype: object\n",
      "[Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-Penn-415-T1C-imagingVolume.nrrd'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 279, in generate_from_features\n",
      "    t1_masked = load_image(t1_image_file, t1_seg_file, verbose=verbose)\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 240, in load_image\n",
      "    image, _ = nrrd.read(image_path)\n",
      "  File \"/home/user1/.local/share/virtualenvs/renal-mri-NanAjWL7/lib/python3.6/site-packages/nrrd/reader.py\", line 427, in read\n",
      "    with open(filename, 'rb') as fh:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-Penn-415-T1C-imagingVolume.nrrd'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 75/446 [00:20<01:01,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "Exception occurred for: patient    Kidney-CHOP-004\n",
      "volume            0.658451\n",
      "outcome             benign\n",
      "age               0.149425\n",
      "sex                      1\n",
      "sort                 train\n",
      "Name: Kidney-CHOP-004, dtype: object\n",
      "[Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-CHOP-004-T1C-imagingVolume.nrrd'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 279, in generate_from_features\n",
      "    t1_masked = load_image(t1_image_file, t1_seg_file, verbose=verbose)\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 240, in load_image\n",
      "    image, _ = nrrd.read(image_path)\n",
      "  File \"/home/user1/.local/share/virtualenvs/renal-mri-NanAjWL7/lib/python3.6/site-packages/nrrd/reader.py\", line 427, in read\n",
      "    with open(filename, 'rb') as fh:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-CHOP-004-T1C-imagingVolume.nrrd'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 218/446 [01:13<01:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "Exception occurred for: patient    Kidney-Penn-153\n",
      "volume            0.658695\n",
      "outcome          malignant\n",
      "age               0.609195\n",
      "sex                      1\n",
      "sort            unassigned\n",
      "Name: Kidney-Penn-153, dtype: object\n",
      "[Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-Penn-153-T1C-imagingVolume.nrrd'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 279, in generate_from_features\n",
      "    t1_masked = load_image(t1_image_file, t1_seg_file, verbose=verbose)\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 240, in load_image\n",
      "    image, _ = nrrd.read(image_path)\n",
      "  File \"/home/user1/.local/share/virtualenvs/renal-mri-NanAjWL7/lib/python3.6/site-packages/nrrd/reader.py\", line 427, in read\n",
      "    with open(filename, 'rb') as fh:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-Penn-153-T1C-imagingVolume.nrrd'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 223/446 [01:16<01:25,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "Exception occurred for: patient    Kidney-Penn-029\n",
      "volume            0.658486\n",
      "outcome          malignant\n",
      "age               0.643678\n",
      "sex                      1\n",
      "sort            unassigned\n",
      "Name: Kidney-Penn-029, dtype: object\n",
      "[Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-Penn-029-T1C-imagingVolume.nrrd'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 279, in generate_from_features\n",
      "    t1_masked = load_image(t1_image_file, t1_seg_file, verbose=verbose)\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 240, in load_image\n",
      "    image, _ = nrrd.read(image_path)\n",
      "  File \"/home/user1/.local/share/virtualenvs/renal-mri-NanAjWL7/lib/python3.6/site-packages/nrrd/reader.py\", line 427, in read\n",
      "    with open(filename, 'rb') as fh:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-Penn-029-T1C-imagingVolume.nrrd'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 446/446 [02:47<00:00,  1.99it/s]\n",
      " 19%|█▉        | 24/127 [00:07<00:34,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "Exception occurred for: patient    Kidney-Penn-007\n",
      "volume            0.658458\n",
      "outcome             benign\n",
      "age               0.689655\n",
      "sex                      1\n",
      "sort            unassigned\n",
      "Name: Kidney-Penn-007, dtype: object\n",
      "[Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-Penn-007-T1C-imagingVolume.nrrd'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 279, in generate_from_features\n",
      "    t1_masked = load_image(t1_image_file, t1_seg_file, verbose=verbose)\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 240, in load_image\n",
      "    image, _ = nrrd.read(image_path)\n",
      "  File \"/home/user1/.local/share/virtualenvs/renal-mri-NanAjWL7/lib/python3.6/site-packages/nrrd/reader.py\", line 427, in read\n",
      "    with open(filename, 'rb') as fh:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-Penn-007-T1C-imagingVolume.nrrd'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 29/127 [00:10<00:50,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "Exception occurred for: patient    Kidney-Penn-080\n",
      "volume            0.660122\n",
      "outcome             benign\n",
      "age               0.793103\n",
      "sex                      1\n",
      "sort            unassigned\n",
      "Name: Kidney-Penn-080, dtype: object\n",
      "[Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-Penn-080-T1C-imagingVolume.nrrd'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 279, in generate_from_features\n",
      "    t1_masked = load_image(t1_image_file, t1_seg_file, verbose=verbose)\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 240, in load_image\n",
      "    image, _ = nrrd.read(image_path)\n",
      "  File \"/home/user1/.local/share/virtualenvs/renal-mri-NanAjWL7/lib/python3.6/site-packages/nrrd/reader.py\", line 427, in read\n",
      "    with open(filename, 'rb') as fh:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-Penn-080-T1C-imagingVolume.nrrd'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 75/127 [00:30<00:13,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "Exception occurred for: patient    Kidney-Penn-115\n",
      "volume            0.658593\n",
      "outcome          malignant\n",
      "age               0.655172\n",
      "sex                      0\n",
      "sort            unassigned\n",
      "Name: Kidney-Penn-115, dtype: object\n",
      "[Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-Penn-115-T1C-imagingVolume.nrrd'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 279, in generate_from_features\n",
      "    t1_masked = load_image(t1_image_file, t1_seg_file, verbose=verbose)\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 240, in load_image\n",
      "    image, _ = nrrd.read(image_path)\n",
      "  File \"/home/user1/.local/share/virtualenvs/renal-mri-NanAjWL7/lib/python3.6/site-packages/nrrd/reader.py\", line 427, in read\n",
      "    with open(filename, 'rb') as fh:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-Penn-115-T1C-imagingVolume.nrrd'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 84/127 [00:35<00:17,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "Exception occurred for: patient    Kidney-Penn-266\n",
      "volume            0.658453\n",
      "outcome          malignant\n",
      "age               0.632184\n",
      "sex                      1\n",
      "sort            unassigned\n",
      "Name: Kidney-Penn-266, dtype: object\n",
      "[Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-Penn-266-T1C-imagingVolume.nrrd'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 279, in generate_from_features\n",
      "    t1_masked = load_image(t1_image_file, t1_seg_file, verbose=verbose)\n",
      "  File \"/home/user1/intrepidlemon/renal-mri/data.py\", line 240, in load_image\n",
      "    image, _ = nrrd.read(image_path)\n",
      "  File \"/home/user1/.local/share/virtualenvs/renal-mri-NanAjWL7/lib/python3.6/site-packages/nrrd/reader.py\", line 427, in read\n",
      "    with open(filename, 'rb') as fh:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/data/intrepidlemon/renal/20190617-preprocessed/Kidney-Penn-266-T1C-imagingVolume.nrrd'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:54<00:00,  2.32it/s]\n",
      "100%|██████████| 63/63 [00:18<00:00,  4.74it/s]\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "result = Result.query.filter(Result.uuid == UUIDS[0]).first()\n",
    "train_set, validation_set, test_set = data(seed=uuid.UUID(result.split_seed), label_form=result.label_form, input_form=result.input_form, train_shuffle=False, test_shuffle=False, validation_shuffle=False, train_augment=False, validation_augment=False, test_augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODALITIES = [\n",
    "    \"features\",     \n",
    "#    \"t1-sensitive\",\n",
    "    \"t2\",\n",
    "    \"t1\",\n",
    "#    \"t2-specific\",\n",
    "    \"ensemble\", \n",
    "]\n",
    "\n",
    "MODALITY_KEY = {\n",
    "    \"features\": \"Clinical\",     \n",
    "    \"t1\": \"T1C\", \n",
    "    \"t2\": \"T2WI\", \n",
    "    \"t1-sensitive\": \"T1C Sensitive\", \n",
    "    \"t2-sensitive\": \"T2WI Sensitive\",     \n",
    "    \"t1-specific\": \"T1C Specific\", \n",
    "    \"t2-specific\": \"T2WI Specific\",         \n",
    "    \"ensemble\": \"Ensemble\", \n",
    "}\n",
    "\n",
    "def get_pr_data_for_modality(dataset, comparison_models=[]): \n",
    "    results = list()\n",
    "    points = list()\n",
    "    for modality in MODALITIES: \n",
    "        labels = dataset[\"{}-labels\".format(modality)]\n",
    "        probabilities = dataset[\"{}-probabilities\".format(modality)]\n",
    "        predictions = dataset[\"{}-predictions\".format(modality)]\n",
    "        print(modality, len(labels), len(probabilities), len(predictions))\n",
    "        acc = accuracy_score(labels, predictions)\n",
    "        precision, recall, _ = precision_recall_curve(labels, probabilities)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        stats = calculate_confusion_matrix_stats_predictions(labels, predictions)\n",
    "        points.append({\n",
    "            \"modality\": \"{} (auc={:.2f}, acc={:.2f})\".format(MODALITY_KEY[modality], pr_auc, acc),\n",
    "            \"precision\": stats[\"PPV\"][1],\n",
    "            \"recall\": stats[\"TPR\"][1],\n",
    "        })\n",
    "        for p, r in zip(precision, recall): \n",
    "            results.append({ \"precision\": p, \"recall\": r, \"modality\": \"{} (auc={:.2f}, acc={:.2f})\".format(MODALITY_KEY[modality], pr_auc, acc)})\n",
    "    for probabilities in comparison_models: \n",
    "        modality = \"Radiomics\"\n",
    "        labels = dataset[\"t1-labels\"]\n",
    "        predictions = [p > 0.5 for p in probabilities]\n",
    "        print(modality, len(labels), len(probabilities), len(predictions))\n",
    "        precision, recall, _ = precision_recall_curve(labels, probabilities)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        stats = calculate_confusion_matrix_stats_predictions(labels, predictions)\n",
    "        acc = accuracy_score(labels, predictions)\n",
    "        points.append({\n",
    "            \"modality\": \"{} (auc={:.2f}, acc={:.2f})\".format(MODALITY_KEY[modality], pr_auc, acc),\n",
    "            \"precision\": stats[\"PPV\"][1],\n",
    "            \"recall\": stats[\"TPR\"][1],\n",
    "        })\n",
    "        for p, r in zip(precision, recall): \n",
    "            results.append({ \"precision\": p, \"recall\": r, \"modality\": \"{} (auc={:.2f}, acc={:.2f})\".format(MODALITY_KEY[modality], pr_auc, acc)})           \n",
    "    return results, pr_auc, []\n",
    "        \n",
    "def plot_multiple_precision_recall(dataset, experts=[], comparison_models=[]):\n",
    "    results, auc, points = get_pr_data_for_modality(dataset, comparison_models)        \n",
    "    if len(experts) > 0:\n",
    "        for i, expert in enumerate(experts): \n",
    "            labels = dataset[\"t1-labels\"]\n",
    "            predictions = expert\n",
    "            stats = calculate_confusion_matrix_stats_predictions(labels, predictions)\n",
    "            acc = accuracy_score(labels, predictions)\n",
    "            points.append({\n",
    "                \"precision\": stats[\"PPV\"][1],\n",
    "                \"recall\": stats[\"TPR\"][1],                \n",
    "                \"experts\": \"Expert {} (acc={:.2f})\".format(i + 1, acc), \n",
    "            })\n",
    "    fig, ax = plt.subplots()\n",
    "    seaborn.lineplot(\n",
    "        data=pandas.DataFrame(results),\n",
    "        x=\"recall\",\n",
    "        y=\"precision\",\n",
    "        hue=\"modality\",\n",
    "        ax=ax, \n",
    "        err_style=None,\n",
    "    )\n",
    "    if points: \n",
    "        seaborn.scatterplot(\n",
    "            data=pandas.DataFrame(points),\n",
    "            x=\"recall\",\n",
    "            y=\"precision\",\n",
    "            hue=\"experts\",\n",
    "            style=\"experts\",                        \n",
    "            markers=[\"o\", \"v\", \"s\", \"P\"],\n",
    "            palette={ p[\"experts\"]: \"black\" for p in points },            \n",
    "            ax=ax,\n",
    "        )\n",
    "    ax.set_ylim(0.5, 1.04)\n",
    "    ax.set_xlim(-0.04, 1.02)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    return fig\n",
    "\n",
    "def get_roc_data_for_modality(dataset, comparison_models=[]): \n",
    "    results = list()\n",
    "    points = list()\n",
    "    for modality in MODALITIES: \n",
    "        labels = dataset[\"{}-labels\".format(modality)]\n",
    "        probabilities = dataset[\"{}-probabilities\".format(modality)]\n",
    "        predictions = dataset[\"{}-predictions\".format(modality)]\n",
    "        fpr, tpr, _ = roc_curve(labels, probabilities, drop_intermediate=False)\n",
    "        roc_auc = roc_auc_score(labels, probabilities)\n",
    "        stats = calculate_confusion_matrix_stats_predictions(labels, predictions)\n",
    "        acc = accuracy_score(labels, predictions)\n",
    "        points.append({\n",
    "            \"modality\": \"{} (auc={:.2f}, acc={:.2f})\".format(MODALITY_KEY[modality], roc_auc, acc),\n",
    "            \"fpr\": stats[\"FPR\"][1],\n",
    "            \"tpr\": stats[\"TPR\"][1],\n",
    "        })\n",
    "        for f, t in zip(fpr, tpr): \n",
    "            results.append({ \"fpr\": f, \"tpr\": t, \"modality\": \"{} (auc={:.2f}, acc={:.2f})\".format(MODALITY_KEY[modality], roc_auc, acc)})\n",
    "    for probabilities in comparison_models: \n",
    "        modality = \"Radiomics\"\n",
    "        labels = dataset[\"t1-labels\"]\n",
    "        predictions = [p > 0.5 for p in probabilities]\n",
    "        fpr, tpr, _ = roc_curve(labels, probabilities, drop_intermediate=False)\n",
    "        roc_auc = roc_auc_score(labels, probabilities)\n",
    "        stats = calculate_confusion_matrix_stats_predictions(labels, predictions)\n",
    "        acc = accuracy_score(labels, predictions)\n",
    "        points.append({\n",
    "            \"modality\": \"{} (auc={:.2f}, acc={:.2f})\".format(MODALITY_KEY[modality], roc_auc, acc),\n",
    "            \"fpr\": stats[\"FPR\"][1],\n",
    "            \"tpr\": stats[\"TPR\"][1],\n",
    "        })\n",
    "        for f, t in zip(fpr, tpr): \n",
    "            results.append({ \"fpr\": f, \"tpr\": t, \"modality\": \"{} (auc={:.2f}, acc={:.2f})\".format(MODALITY_KEY[modality], roc_auc, acc)})        \n",
    "    return results, roc_auc, []\n",
    "        \n",
    "def plot_multiple_roc_curve(dataset, experts=[], comparison_models=[]):\n",
    "    results, auc, points = get_roc_data_for_modality(dataset, comparison_models)\n",
    "    if len(experts) > 0:\n",
    "        for i, expert in enumerate(experts): \n",
    "            labels = dataset[\"t1-labels\"]\n",
    "            predictions = expert\n",
    "            stats = calculate_confusion_matrix_stats_predictions(labels, predictions)\n",
    "            acc = accuracy_score(labels, predictions)            \n",
    "            points.append({\n",
    "                \"fpr\": stats[\"FPR\"][1],\n",
    "                \"tpr\": stats[\"TPR\"][1],\n",
    "                \"experts\": \"Expert {} (acc={:.2f})\".format(i + 1, acc),                 \n",
    "            })\n",
    "    fig, ax = plt.subplots()\n",
    "    seaborn.lineplot(\n",
    "        data=pandas.DataFrame(results),\n",
    "        x=\"fpr\",\n",
    "        y=\"tpr\",\n",
    "        hue=\"modality\",\n",
    "        ax=ax,\n",
    "        err_style=None,\n",
    "    )\n",
    "    if points:     \n",
    "        seaborn.scatterplot(\n",
    "            data=pandas.DataFrame(points),\n",
    "            x=\"fpr\",\n",
    "            y=\"tpr\",\n",
    "            hue=\"experts\",\n",
    "            style=\"experts\",            \n",
    "            ax=ax,\n",
    "            markers=[\"o\", \"v\", \"s\", \"P\"],\n",
    "            palette={ p[\"experts\"]: \"black\" for p in points },\n",
    "        )\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--')\n",
    "    ax.set_ylim(-0.04, 1.04)\n",
    "    ax.set_xlim(-0.04, 1.02)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    return fig\n",
    "\n",
    "def get_statistics(dataset, experts=[], comparison_models=[]): \n",
    "    results = list()\n",
    "    for modality in MODALITIES: \n",
    "        labels = dataset[\"{}-labels\".format(modality)]\n",
    "        probabilities = dataset[\"{}-probabilities\".format(modality)]\n",
    "        predictions = dataset[\"{}-predictions\".format(modality)]\n",
    "        roc_auc = roc_auc_score(labels, probabilities)\n",
    "        precision, recall, _ = precision_recall_curve(labels, probabilities)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        f1 = f1_score(labels, predictions)\n",
    "        d = {\n",
    "            \"F1 Score\": [f1, f1],            \n",
    "            \"ROC AUC\": [roc_auc, roc_auc], \n",
    "            \"PR AUC\": [pr_auc, pr_auc],\n",
    "            **calculate_confusion_matrix_stats_predictions(labels, predictions), \n",
    "            \"Modality\": [modality.capitalize(), modality.capitalize()], \n",
    "            \"Total\": [len(labels), len(labels)], \n",
    "            \"Malignant\": [len([l for l in labels if l]), len([l for l in labels if l])], \n",
    "            \"Benign\": [len([l for l in labels if not l]), len([l for l in labels if not l])], \n",
    "        } \n",
    "        # remove more that are not relevant to imbalanced datasets\n",
    "        del d[\"TP\"]\n",
    "        del d[\"TN\"]\n",
    "        del d[\"FN\"]\n",
    "        del d[\"FP\"]    \n",
    "        del d[\"AM\"]        \n",
    "        del d[\"GM\"]\n",
    "        del d[\"FPR\"]\n",
    "        del d[\"FNR\"]\n",
    "        d[\"Acc (95% CI)\"] = [\"\", \"{:.2f} ({:.2f}-{:.2f})\".format(d[\"Acc\"][1], *adjusted_wald(d[\"Acc\"][1], len(labels)))]\n",
    "        d[\"TPR (95% CI)\"] = [\"\", \"{:.2f} ({:.2f}-{:.2f})\".format(d[\"TPR\"][1], *adjusted_wald(d[\"TPR\"][1], len([l for l in labels if l])))]\n",
    "        d[\"TNR (95% CI)\"] = [\"\", \"{:.2f} ({:.2f}-{:.2f})\".format(d[\"TNR\"][1], *adjusted_wald(d[\"TNR\"][1], len([l for l in labels if not l])))]\n",
    "        results.append(pandas.DataFrame(d).iloc[[1]])\n",
    "    for i, expert in enumerate(experts): \n",
    "        labels = dataset[\"ensemble-labels\"]\n",
    "        predictions = expert\n",
    "        f1 = f1_score(labels, predictions)        \n",
    "        d = {\n",
    "            \"F1 Score\": [f1, f1],            \n",
    "            **calculate_confusion_matrix_stats_predictions(labels, predictions),             \n",
    "            \"Modality\": [\"Expert {}\".format(i + 1), \"Expert {}\".format(i + 1)], \n",
    "            \"Total\": [len(labels), len(labels)], \n",
    "            \"Malignant\": [len([l for l in labels if l]), len([l for l in labels if l])], \n",
    "            \"Benign\": [len([l for l in labels if not l]), len([l for l in labels if not l])],             \n",
    "        }\n",
    "        # remove more that are not relevant to imbalanced datasets (remove from article too)\n",
    "        del d[\"TP\"]\n",
    "        del d[\"TN\"]\n",
    "        del d[\"FN\"]\n",
    "        del d[\"FP\"]               \n",
    "        del d[\"AM\"]        \n",
    "        del d[\"GM\"]\n",
    "        del d[\"FPR\"]\n",
    "        del d[\"FNR\"]        \n",
    "        d[\"Acc (95% CI)\"] = [\"\", \"{:.2f} ({:.2f}-{:.2f})\".format(d[\"Acc\"][1], *adjusted_wald(d[\"Acc\"][1], len(labels)))]\n",
    "        d[\"TPR (95% CI)\"] = [\"\", \"{:.2f} ({:.2f}-{:.2f})\".format(d[\"TPR\"][1], *adjusted_wald(d[\"TPR\"][1], len([l for l in labels if l])))]\n",
    "        d[\"TNR (95% CI)\"] = [\"\", \"{:.2f} ({:.2f}-{:.2f})\".format(d[\"TNR\"][1], *adjusted_wald(d[\"TNR\"][1], len([l for l in labels if not l])))]        \n",
    "        results.append(pandas.DataFrame(d).iloc[[1]])\n",
    "    for probabilities in comparison_models: \n",
    "        labels = dataset[\"ensemble-labels\"]\n",
    "        predictions = [p > 0.5 for p in probabilities]\n",
    "        roc_auc = roc_auc_score(labels, probabilities)\n",
    "        precision, recall, _ = precision_recall_curve(labels, probabilities)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        f1 = f1_score(labels, predictions)\n",
    "        d = {\n",
    "            \"F1 Score\": [f1, f1],            \n",
    "            \"ROC AUC\": [roc_auc, roc_auc], \n",
    "            \"PR AUC\": [pr_auc, pr_auc],\n",
    "            **calculate_confusion_matrix_stats_predictions(labels, predictions), \n",
    "            \"Modality\": [\"Radiomics\", \"Radiomics\"], \n",
    "            \"Total\": [len(labels), len(labels)], \n",
    "            \"Malignant\": [len([l for l in labels if l]), len([l for l in labels if l])], \n",
    "            \"Benign\": [len([l for l in labels if not l]), len([l for l in labels if not l])],             \n",
    "        } \n",
    "        # remove more that are not relevant to imbalanced datasets (remove from article too)\n",
    "        del d[\"TP\"]\n",
    "        del d[\"TN\"]\n",
    "        del d[\"FN\"]\n",
    "        del d[\"FP\"]         \n",
    "        del d[\"AM\"]        \n",
    "        del d[\"GM\"]\n",
    "        del d[\"FPR\"]\n",
    "        del d[\"FNR\"]\n",
    "        d[\"Acc (95% CI)\"] = [\"\", \"{:.2f} ({:.2f}-{:.2f})\".format(d[\"Acc\"][1], *adjusted_wald(d[\"Acc\"][1], len(labels)))]\n",
    "        d[\"TPR (95% CI)\"] = [\"\", \"{:.2f} ({:.2f}-{:.2f})\".format(d[\"TPR\"][1], *adjusted_wald(d[\"TPR\"][1], len([l for l in labels if l])))]\n",
    "        d[\"TNR (95% CI)\"] = [\"\", \"{:.2f} ({:.2f}-{:.2f})\".format(d[\"TNR\"][1], *adjusted_wald(d[\"TNR\"][1], len([l for l in labels if not l])))]        \n",
    "        results.append(pandas.DataFrame(d).iloc[[1]])\n",
    "\n",
    "    return pandas.concat(results, axis=0, sort=False).set_index(\"Modality\")\n",
    "\n",
    "def get_experts_for_names(features, names, experts=[\"expert1\", \"expert2\"], transform=int, default=0): \n",
    "    result = list()\n",
    "    for e in experts: \n",
    "        expert_results = list()\n",
    "        for n in names: \n",
    "            f = features.get(n, None)\n",
    "            if f is None: \n",
    "                print(\"error, cannot find {}\".format(n))\n",
    "                expert_results.append(default)\n",
    "                continue\n",
    "            r = f.get(e, default)\n",
    "            if r == \"\": \n",
    "                r = 0\n",
    "            r = transform(r)\n",
    "            expert_results.append(r)\n",
    "        result.append(expert_results)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error, cannot find Kidney-CHOP-061\n",
      "error, cannot find Kidney-CHOP-062\n",
      "error, cannot find Kidney-CHOP-092\n",
      "error, cannot find Kidney-CHOP-074\n",
      "error, cannot find Kidney-Penn-380\n",
      "error, cannot find Kidney-Penn-411\n",
      "error, cannot find Kidney-Penn-413\n",
      "error, cannot find Kidney-CHOP-045\n",
      "error, cannot find Kidney-CHOP-010\n",
      "error, cannot find Kidney-CHOP-065\n",
      "error, cannot find Kidney-Penn-402\n",
      "error, cannot find Kidney-CHOP-060\n",
      "error, cannot find Kidney-CHOP-042\n",
      "error, cannot find Kidney-CHOP-026\n",
      "error, cannot find Kidney-CHOP-067\n",
      "error, cannot find Kidney-CHOP-014\n",
      "error, cannot find Kidney-CHOP-057\n",
      "error, cannot find Kidney-CHOP-019\n",
      "error, cannot find Kidney-CHOP-063\n",
      "error, cannot find Kidney-Penn-420\n",
      "error, cannot find Kidney-CHOP-021\n",
      "error, cannot find Kidney-CHOP-031\n",
      "error, cannot find Kidney-CHOP-106\n",
      "error, cannot find Kidney-CHOP-020\n",
      "error, cannot find Kidney-CHOP-072\n",
      "error, cannot find Kidney-CHOP-064\n",
      "error, cannot find Kidney-Penn-388\n",
      "error, cannot find Kidney-CHOP-091\n",
      "error, cannot find Kidney-CHOP-007\n",
      "error, cannot find Kidney-CHOP-023\n",
      "error, cannot find Kidney-CHOP-034\n",
      "error, cannot find Kidney-Penn-432\n",
      "error, cannot find Kidney-Penn-419\n",
      "error, cannot find Kidney-CHOP-102\n",
      "error, cannot find Kidney-Penn-396\n",
      "error, cannot find Kidney-Penn-412\n",
      "error, cannot find Kidney-CHOP-110\n",
      "error, cannot find Kidney-Penn-427\n",
      "error, cannot find Kidney-CHOP-008\n",
      "error, cannot find Kidney-CHOP-013\n",
      "error, cannot find Kidney-CHOP-103\n",
      "error, cannot find Kidney-CHOP-108\n",
      "error, cannot find Kidney-CHOP-041\n",
      "error, cannot find Kidney-CHOP-101\n",
      "error, cannot find Kidney-Penn-421\n",
      "error, cannot find Kidney-CHOP-084\n",
      "error, cannot find Kidney-Penn-426\n",
      "error, cannot find Kidney-CHOP-030\n",
      "error, cannot find Kidney-Penn-403\n",
      "error, cannot find Kidney-Penn-401\n",
      "error, cannot find Kidney-Penn-385\n",
      "error, cannot find Kidney-CHOP-011\n",
      "error, cannot find Kidney-CHOP-022\n",
      "error, cannot find Kidney-CHOP-082\n",
      "error, cannot find Kidney-CHOP-048\n",
      "error, cannot find Kidney-CHOP-038\n",
      "error, cannot find Kidney-CHOP-081\n",
      "error, cannot find Kidney-CHOP-001\n",
      "error, cannot find Kidney-CHOP-078\n",
      "error, cannot find Kidney-Penn-393\n",
      "error, cannot find Kidney-Penn-384\n",
      "error, cannot find Kidney-CHOP-069\n",
      "error, cannot find Kidney-Penn-428\n",
      "error, cannot find Kidney-CHOP-090\n",
      "error, cannot find Kidney-CHOP-052\n",
      "error, cannot find Kidney-CHOP-096\n",
      "error, cannot find Kidney-Penn-391\n",
      "error, cannot find Kidney-CHOP-025\n",
      "error, cannot find Kidney-Penn-414\n",
      "error, cannot find Kidney-Penn-381\n",
      "error, cannot find Kidney-Penn-416\n",
      "error, cannot find Kidney-CHOP-105\n",
      "error, cannot find Kidney-Penn-422\n",
      "error, cannot find Kidney-Penn-407\n",
      "error, cannot find Kidney-Penn-410\n",
      "error, cannot find Kidney-Penn-386\n",
      "error, cannot find Kidney-CHOP-076\n",
      "error, cannot find Kidney-Penn-379\n",
      "error, cannot find Kidney-CHOP-071\n",
      "error, cannot find Kidney-CHOP-051\n",
      "error, cannot find Kidney-CHOP-056\n",
      "error, cannot find Kidney-CHOP-098\n",
      "error, cannot find Kidney-CHOP-054\n",
      "error, cannot find Kidney-CHOP-080\n",
      "error, cannot find Kidney-CHOP-039\n",
      "error, cannot find Kidney-CHOP-073\n",
      "error, cannot find Kidney-CHOP-016\n",
      "error, cannot find Kidney-Penn-424\n",
      "error, cannot find Kidney-Penn-400\n",
      "error, cannot find Kidney-Penn-387\n",
      "error, cannot find Kidney-CHOP-099\n",
      "error, cannot find Kidney-CHOP-024\n",
      "error, cannot find Kidney-CHOP-028\n",
      "error, cannot find Kidney-CHOP-085\n",
      "error, cannot find Kidney-CHOP-015\n",
      "error, cannot find Kidney-CHOP-058\n",
      "error, cannot find Kidney-CHOP-077\n",
      "error, cannot find Kidney-CHOP-112\n",
      "error, cannot find Kidney-CHOP-094\n",
      "error, cannot find Kidney-Penn-429\n",
      "error, cannot find Kidney-CHOP-046\n",
      "error, cannot find Kidney-Penn-395\n",
      "error, cannot find Kidney-Penn-408\n",
      "error, cannot find Kidney-CHOP-047\n",
      "error, cannot find Kidney-CHOP-097\n",
      "error, cannot find Kidney-Penn-418\n",
      "error, cannot find Kidney-CHOP-009\n",
      "error, cannot find Kidney-CHOP-044\n",
      "error, cannot find Kidney-CHOP-070\n",
      "error, cannot find Kidney-Penn-399\n",
      "error, cannot find Kidney-CHOP-040\n",
      "error, cannot find Kidney-CHOP-043\n",
      "error, cannot find Kidney-CHOP-002\n",
      "error, cannot find Kidney-CHOP-033\n",
      "error, cannot find Kidney-CHOP-012\n",
      "error, cannot find Kidney-Penn-394\n",
      "error, cannot find Kidney-Penn-390\n",
      "error, cannot find Kidney-CHOP-050\n",
      "error, cannot find Kidney-CHOP-068\n",
      "error, cannot find Kidney-Penn-397\n",
      "error, cannot find Kidney-CHOP-107\n",
      "error, cannot find Kidney-CHOP-095\n",
      "error, cannot find Kidney-CHOP-029\n",
      "error, cannot find Kidney-Penn-392\n",
      "error, cannot find Kidney-CHOP-018\n",
      "error, cannot find Kidney-CHOP-005\n",
      "error, cannot find Kidney-CHOP-088\n",
      "error, cannot find Kidney-CHOP-036\n",
      "error, cannot find Kidney-CHOP-003\n",
      "error, cannot find Kidney-CHOP-055\n",
      "error, cannot find Kidney-CHOP-059\n",
      "error, cannot find Kidney-CHOP-104\n",
      "error, cannot find Kidney-CHOP-079\n",
      "error, cannot find Kidney-Penn-398\n",
      "error, cannot find Kidney-CHOP-075\n",
      "error, cannot find Kidney-Penn-378\n",
      "error, cannot find Kidney-Penn-406\n",
      "error, cannot find Kidney-Penn-417\n",
      "error, cannot find Kidney-CHOP-086\n",
      "error, cannot find Kidney-CHOP-032\n",
      "error, cannot find Kidney-CHOP-089\n",
      "error, cannot find Kidney-CHOP-083\n",
      "error, cannot find Kidney-CHOP-006\n",
      "error, cannot find Kidney-Penn-383\n",
      "error, cannot find Kidney-Penn-431\n",
      "error, cannot find Kidney-CHOP-035\n",
      "error, cannot find Kidney-CHOP-037\n",
      "error, cannot find Kidney-CHOP-087\n",
      "error, cannot find Kidney-CHOP-066\n",
      "error, cannot find Kidney-CHOP-027\n",
      "error, cannot find Kidney-Penn-404\n",
      "error, cannot find Kidney-CHOP-093\n",
      "error, cannot find Kidney-CHOP-109\n",
      "error, cannot find Kidney-CHOP-111\n",
      "error, cannot find Kidney-CHOP-053\n",
      "error, cannot find Kidney-Penn-405\n",
      "error, cannot find Kidney-Penn-409\n",
      "error, cannot find Kidney-CHOP-100\n",
      "error, cannot find Kidney-CHOP-049\n",
      "error, cannot find Kidney-CHOP-061\n",
      "error, cannot find Kidney-CHOP-062\n",
      "error, cannot find Kidney-CHOP-092\n",
      "error, cannot find Kidney-CHOP-074\n",
      "error, cannot find Kidney-Penn-380\n",
      "error, cannot find Kidney-Penn-411\n",
      "error, cannot find Kidney-Penn-413\n",
      "error, cannot find Kidney-CHOP-045\n",
      "error, cannot find Kidney-CHOP-010\n",
      "error, cannot find Kidney-CHOP-065\n",
      "error, cannot find Kidney-Penn-402\n",
      "error, cannot find Kidney-CHOP-060\n",
      "error, cannot find Kidney-CHOP-042\n",
      "error, cannot find Kidney-CHOP-026\n",
      "error, cannot find Kidney-CHOP-067\n",
      "error, cannot find Kidney-CHOP-014\n",
      "error, cannot find Kidney-CHOP-057\n",
      "error, cannot find Kidney-CHOP-019\n",
      "error, cannot find Kidney-CHOP-063\n",
      "error, cannot find Kidney-Penn-420\n",
      "error, cannot find Kidney-CHOP-021\n",
      "error, cannot find Kidney-CHOP-031\n",
      "error, cannot find Kidney-CHOP-106\n",
      "error, cannot find Kidney-CHOP-020\n",
      "error, cannot find Kidney-CHOP-072\n",
      "error, cannot find Kidney-CHOP-064\n",
      "error, cannot find Kidney-Penn-388\n",
      "error, cannot find Kidney-CHOP-091\n",
      "error, cannot find Kidney-CHOP-007\n",
      "error, cannot find Kidney-CHOP-023\n",
      "error, cannot find Kidney-CHOP-034\n",
      "error, cannot find Kidney-Penn-432\n",
      "error, cannot find Kidney-Penn-419\n",
      "error, cannot find Kidney-CHOP-102\n",
      "error, cannot find Kidney-Penn-396\n",
      "error, cannot find Kidney-Penn-412\n",
      "error, cannot find Kidney-CHOP-110\n",
      "error, cannot find Kidney-Penn-427\n",
      "error, cannot find Kidney-CHOP-008\n",
      "error, cannot find Kidney-CHOP-013\n",
      "error, cannot find Kidney-CHOP-103\n",
      "error, cannot find Kidney-CHOP-108\n",
      "error, cannot find Kidney-CHOP-041\n",
      "error, cannot find Kidney-CHOP-101\n",
      "error, cannot find Kidney-Penn-421\n",
      "error, cannot find Kidney-CHOP-084\n",
      "error, cannot find Kidney-Penn-426\n",
      "error, cannot find Kidney-CHOP-030\n",
      "error, cannot find Kidney-Penn-403\n",
      "error, cannot find Kidney-Penn-401\n",
      "error, cannot find Kidney-Penn-385\n",
      "error, cannot find Kidney-CHOP-011\n",
      "error, cannot find Kidney-CHOP-022\n",
      "error, cannot find Kidney-CHOP-082\n",
      "error, cannot find Kidney-CHOP-048\n",
      "error, cannot find Kidney-CHOP-038\n",
      "error, cannot find Kidney-CHOP-081\n",
      "error, cannot find Kidney-CHOP-001\n",
      "error, cannot find Kidney-CHOP-078\n",
      "error, cannot find Kidney-Penn-393\n",
      "error, cannot find Kidney-Penn-384\n",
      "error, cannot find Kidney-CHOP-069\n",
      "error, cannot find Kidney-Penn-428\n",
      "error, cannot find Kidney-CHOP-090\n",
      "error, cannot find Kidney-CHOP-052\n",
      "error, cannot find Kidney-CHOP-096\n",
      "error, cannot find Kidney-Penn-391\n",
      "error, cannot find Kidney-CHOP-025\n",
      "error, cannot find Kidney-Penn-414\n",
      "error, cannot find Kidney-Penn-381\n",
      "error, cannot find Kidney-Penn-416\n",
      "error, cannot find Kidney-CHOP-105\n",
      "error, cannot find Kidney-Penn-422\n",
      "error, cannot find Kidney-Penn-407\n",
      "error, cannot find Kidney-Penn-410\n",
      "error, cannot find Kidney-Penn-386\n",
      "error, cannot find Kidney-CHOP-076\n",
      "error, cannot find Kidney-Penn-379\n",
      "error, cannot find Kidney-CHOP-071\n",
      "error, cannot find Kidney-CHOP-051\n",
      "error, cannot find Kidney-CHOP-056\n",
      "error, cannot find Kidney-CHOP-098\n",
      "error, cannot find Kidney-CHOP-054\n",
      "error, cannot find Kidney-CHOP-080\n",
      "error, cannot find Kidney-CHOP-039\n",
      "error, cannot find Kidney-CHOP-073\n",
      "error, cannot find Kidney-CHOP-016\n",
      "error, cannot find Kidney-Penn-424\n",
      "error, cannot find Kidney-Penn-400\n",
      "error, cannot find Kidney-Penn-387\n",
      "error, cannot find Kidney-CHOP-099\n",
      "error, cannot find Kidney-CHOP-024\n",
      "error, cannot find Kidney-CHOP-028\n",
      "error, cannot find Kidney-CHOP-085\n",
      "error, cannot find Kidney-CHOP-015\n",
      "error, cannot find Kidney-CHOP-058\n",
      "error, cannot find Kidney-CHOP-077\n",
      "error, cannot find Kidney-CHOP-112\n",
      "error, cannot find Kidney-CHOP-094\n",
      "error, cannot find Kidney-Penn-429\n",
      "error, cannot find Kidney-CHOP-046\n",
      "error, cannot find Kidney-Penn-395\n",
      "error, cannot find Kidney-Penn-408\n",
      "error, cannot find Kidney-CHOP-047\n",
      "error, cannot find Kidney-CHOP-097\n",
      "error, cannot find Kidney-Penn-418\n",
      "error, cannot find Kidney-CHOP-009\n",
      "error, cannot find Kidney-CHOP-044\n",
      "error, cannot find Kidney-CHOP-070\n",
      "error, cannot find Kidney-Penn-399\n",
      "error, cannot find Kidney-CHOP-040\n",
      "error, cannot find Kidney-CHOP-043\n",
      "error, cannot find Kidney-CHOP-002\n",
      "error, cannot find Kidney-CHOP-033\n",
      "error, cannot find Kidney-CHOP-012\n",
      "error, cannot find Kidney-Penn-394\n",
      "error, cannot find Kidney-Penn-390\n",
      "error, cannot find Kidney-CHOP-050\n",
      "error, cannot find Kidney-CHOP-068\n",
      "error, cannot find Kidney-Penn-397\n",
      "error, cannot find Kidney-CHOP-107\n",
      "error, cannot find Kidney-CHOP-095\n",
      "error, cannot find Kidney-CHOP-029\n",
      "error, cannot find Kidney-Penn-392\n",
      "error, cannot find Kidney-CHOP-018\n",
      "error, cannot find Kidney-CHOP-005\n",
      "error, cannot find Kidney-CHOP-088\n",
      "error, cannot find Kidney-CHOP-036\n",
      "error, cannot find Kidney-CHOP-003\n",
      "error, cannot find Kidney-CHOP-055\n",
      "error, cannot find Kidney-CHOP-059\n",
      "error, cannot find Kidney-CHOP-104\n",
      "error, cannot find Kidney-CHOP-079\n",
      "error, cannot find Kidney-Penn-398\n",
      "error, cannot find Kidney-CHOP-075\n",
      "error, cannot find Kidney-Penn-378\n",
      "error, cannot find Kidney-Penn-406\n",
      "error, cannot find Kidney-Penn-417\n",
      "error, cannot find Kidney-CHOP-086\n",
      "error, cannot find Kidney-CHOP-032\n",
      "error, cannot find Kidney-CHOP-089\n",
      "error, cannot find Kidney-CHOP-083\n",
      "error, cannot find Kidney-CHOP-006\n",
      "error, cannot find Kidney-Penn-383\n",
      "error, cannot find Kidney-Penn-431\n",
      "error, cannot find Kidney-CHOP-035\n",
      "error, cannot find Kidney-CHOP-037\n",
      "error, cannot find Kidney-CHOP-087\n",
      "error, cannot find Kidney-CHOP-066\n",
      "error, cannot find Kidney-CHOP-027\n",
      "error, cannot find Kidney-Penn-404\n",
      "error, cannot find Kidney-CHOP-093\n",
      "error, cannot find Kidney-CHOP-109\n",
      "error, cannot find Kidney-CHOP-111\n",
      "error, cannot find Kidney-CHOP-053\n",
      "error, cannot find Kidney-Penn-405\n",
      "error, cannot find Kidney-Penn-409\n",
      "error, cannot find Kidney-CHOP-100\n",
      "error, cannot find Kidney-CHOP-049\n",
      "error, cannot find Kidney-CHOP-061\n",
      "error, cannot find Kidney-CHOP-062\n",
      "error, cannot find Kidney-CHOP-092\n",
      "error, cannot find Kidney-CHOP-074\n",
      "error, cannot find Kidney-Penn-380\n",
      "error, cannot find Kidney-Penn-411\n",
      "error, cannot find Kidney-Penn-413\n",
      "error, cannot find Kidney-CHOP-045\n",
      "error, cannot find Kidney-CHOP-010\n",
      "error, cannot find Kidney-CHOP-065\n",
      "error, cannot find Kidney-Penn-402\n",
      "error, cannot find Kidney-CHOP-060\n",
      "error, cannot find Kidney-CHOP-042\n",
      "error, cannot find Kidney-CHOP-026\n",
      "error, cannot find Kidney-CHOP-067\n",
      "error, cannot find Kidney-CHOP-014\n",
      "error, cannot find Kidney-CHOP-057\n",
      "error, cannot find Kidney-CHOP-019\n",
      "error, cannot find Kidney-CHOP-063\n",
      "error, cannot find Kidney-Penn-420\n",
      "error, cannot find Kidney-CHOP-021\n",
      "error, cannot find Kidney-CHOP-031\n",
      "error, cannot find Kidney-CHOP-106\n",
      "error, cannot find Kidney-CHOP-020\n",
      "error, cannot find Kidney-CHOP-072\n",
      "error, cannot find Kidney-CHOP-064\n",
      "error, cannot find Kidney-Penn-388\n",
      "error, cannot find Kidney-CHOP-091\n",
      "error, cannot find Kidney-CHOP-007\n",
      "error, cannot find Kidney-CHOP-023\n",
      "error, cannot find Kidney-CHOP-034\n",
      "error, cannot find Kidney-Penn-432\n",
      "error, cannot find Kidney-Penn-419\n",
      "error, cannot find Kidney-CHOP-102\n",
      "error, cannot find Kidney-Penn-396\n",
      "error, cannot find Kidney-Penn-412\n",
      "error, cannot find Kidney-CHOP-110\n",
      "error, cannot find Kidney-Penn-427\n",
      "error, cannot find Kidney-CHOP-008\n",
      "error, cannot find Kidney-CHOP-013\n",
      "error, cannot find Kidney-CHOP-103\n",
      "error, cannot find Kidney-CHOP-108\n",
      "error, cannot find Kidney-CHOP-041\n",
      "error, cannot find Kidney-CHOP-101\n",
      "error, cannot find Kidney-Penn-421\n",
      "error, cannot find Kidney-CHOP-084\n",
      "error, cannot find Kidney-Penn-426\n",
      "error, cannot find Kidney-CHOP-030\n",
      "error, cannot find Kidney-Penn-403\n",
      "error, cannot find Kidney-Penn-401\n",
      "error, cannot find Kidney-Penn-385\n",
      "error, cannot find Kidney-CHOP-011\n",
      "error, cannot find Kidney-CHOP-022\n",
      "error, cannot find Kidney-CHOP-082\n",
      "error, cannot find Kidney-CHOP-048\n",
      "error, cannot find Kidney-CHOP-038\n",
      "error, cannot find Kidney-CHOP-081\n",
      "error, cannot find Kidney-CHOP-001\n",
      "error, cannot find Kidney-CHOP-078\n",
      "error, cannot find Kidney-Penn-393\n",
      "error, cannot find Kidney-Penn-384\n",
      "error, cannot find Kidney-CHOP-069\n",
      "error, cannot find Kidney-Penn-428\n",
      "error, cannot find Kidney-CHOP-090\n",
      "error, cannot find Kidney-CHOP-052\n",
      "error, cannot find Kidney-CHOP-096\n",
      "error, cannot find Kidney-Penn-391\n",
      "error, cannot find Kidney-CHOP-025\n",
      "error, cannot find Kidney-Penn-414\n",
      "error, cannot find Kidney-Penn-381\n",
      "error, cannot find Kidney-Penn-416\n",
      "error, cannot find Kidney-CHOP-105\n",
      "error, cannot find Kidney-Penn-422\n",
      "error, cannot find Kidney-Penn-407\n",
      "error, cannot find Kidney-Penn-410\n",
      "error, cannot find Kidney-Penn-386\n",
      "error, cannot find Kidney-CHOP-076\n",
      "error, cannot find Kidney-Penn-379\n",
      "error, cannot find Kidney-CHOP-071\n",
      "error, cannot find Kidney-CHOP-051\n",
      "error, cannot find Kidney-CHOP-056\n",
      "error, cannot find Kidney-CHOP-098\n",
      "error, cannot find Kidney-CHOP-054\n",
      "error, cannot find Kidney-CHOP-080\n",
      "error, cannot find Kidney-CHOP-039\n",
      "error, cannot find Kidney-CHOP-073\n",
      "error, cannot find Kidney-CHOP-016\n",
      "error, cannot find Kidney-Penn-424\n",
      "error, cannot find Kidney-Penn-400\n",
      "error, cannot find Kidney-Penn-387\n",
      "error, cannot find Kidney-CHOP-099\n",
      "error, cannot find Kidney-CHOP-024\n",
      "error, cannot find Kidney-CHOP-028\n",
      "error, cannot find Kidney-CHOP-085\n",
      "error, cannot find Kidney-CHOP-015\n",
      "error, cannot find Kidney-CHOP-058\n",
      "error, cannot find Kidney-CHOP-077\n",
      "error, cannot find Kidney-CHOP-112\n",
      "error, cannot find Kidney-CHOP-094\n",
      "error, cannot find Kidney-Penn-429\n",
      "error, cannot find Kidney-CHOP-046\n",
      "error, cannot find Kidney-Penn-395\n",
      "error, cannot find Kidney-Penn-408\n",
      "error, cannot find Kidney-CHOP-047\n",
      "error, cannot find Kidney-CHOP-097\n",
      "error, cannot find Kidney-Penn-418\n",
      "error, cannot find Kidney-CHOP-009\n",
      "error, cannot find Kidney-CHOP-044\n",
      "error, cannot find Kidney-CHOP-070\n",
      "error, cannot find Kidney-Penn-399\n",
      "error, cannot find Kidney-CHOP-040\n",
      "error, cannot find Kidney-CHOP-043\n",
      "error, cannot find Kidney-CHOP-002\n",
      "error, cannot find Kidney-CHOP-033\n",
      "error, cannot find Kidney-CHOP-012\n",
      "error, cannot find Kidney-Penn-394\n",
      "error, cannot find Kidney-Penn-390\n",
      "error, cannot find Kidney-CHOP-050\n",
      "error, cannot find Kidney-CHOP-068\n",
      "error, cannot find Kidney-Penn-397\n",
      "error, cannot find Kidney-CHOP-107\n",
      "error, cannot find Kidney-CHOP-095\n",
      "error, cannot find Kidney-CHOP-029\n",
      "error, cannot find Kidney-Penn-392\n",
      "error, cannot find Kidney-CHOP-018\n",
      "error, cannot find Kidney-CHOP-005\n",
      "error, cannot find Kidney-CHOP-088\n",
      "error, cannot find Kidney-CHOP-036\n",
      "error, cannot find Kidney-CHOP-003\n",
      "error, cannot find Kidney-CHOP-055\n",
      "error, cannot find Kidney-CHOP-059\n",
      "error, cannot find Kidney-CHOP-104\n",
      "error, cannot find Kidney-CHOP-079\n",
      "error, cannot find Kidney-Penn-398\n",
      "error, cannot find Kidney-CHOP-075\n",
      "error, cannot find Kidney-Penn-378\n",
      "error, cannot find Kidney-Penn-406\n",
      "error, cannot find Kidney-Penn-417\n",
      "error, cannot find Kidney-CHOP-086\n",
      "error, cannot find Kidney-CHOP-032\n",
      "error, cannot find Kidney-CHOP-089\n",
      "error, cannot find Kidney-CHOP-083\n",
      "error, cannot find Kidney-CHOP-006\n",
      "error, cannot find Kidney-Penn-383\n",
      "error, cannot find Kidney-Penn-431\n",
      "error, cannot find Kidney-CHOP-035\n",
      "error, cannot find Kidney-CHOP-037\n",
      "error, cannot find Kidney-CHOP-087\n",
      "error, cannot find Kidney-CHOP-066\n",
      "error, cannot find Kidney-CHOP-027\n",
      "error, cannot find Kidney-Penn-404\n",
      "error, cannot find Kidney-CHOP-093\n",
      "error, cannot find Kidney-CHOP-109\n",
      "error, cannot find Kidney-CHOP-111\n",
      "error, cannot find Kidney-CHOP-053\n",
      "error, cannot find Kidney-Penn-405\n",
      "error, cannot find Kidney-Penn-409\n",
      "error, cannot find Kidney-CHOP-100\n",
      "error, cannot find Kidney-CHOP-049\n",
      "\n",
      "##### Train\n",
      "\n",
      "| Modality   |   F1 Score |   ROC AUC |   PR AUC |   PPV |   NPV |    FDR | Acc (95% CI)     | TPR (95% CI)     | TNR (95% CI)     |\n",
      "|:-----------|-----------:|----------:|---------:|------:|------:|-------:|:-----------------|:-----------------|:-----------------|\n",
      "| Clinical   |      0.848 |     0.772 |    0.736 | 0.779 | 0.864 | 0.221  | 0.80 (0.76-0.84) | 0.93 (0.89-0.96) | 0.63 (0.55-0.69) |\n",
      "| T2         |      0.921 |     0.971 |    0.981 | 0.966 | 0.849 | 0.0340 | 0.91 (0.88-0.93) | 0.88 (0.83-0.91) | 0.96 (0.91-0.98) |\n",
      "| T1         |      0.953 |     0.988 |    0.991 | 0.927 | 0.970 | 0.0733 | 0.94 (0.92-0.96) | 0.98 (0.95-0.99) | 0.89 (0.84-0.93) |\n",
      "| Ensemble   |      0.977 |     0.997 |    0.998 | 0.962 | 0.989 | 0.0376 | 0.97 (0.95-0.98) | 0.99 (0.97-1.00) | 0.95 (0.90-0.97) |\n",
      "| Expert 1   |      0.942 |   N/A     |  N/A     | 0.938 | 0.922 | 0.0615 | 0.93 (0.90-0.95) | 0.95 (0.91-0.97) | 0.91 (0.86-0.95) |\n",
      "| Expert 2   |      0.947 |   N/A     |  N/A     | 0.932 | 0.943 | 0.0677 | 0.94 (0.91-0.96) | 0.96 (0.93-0.98) | 0.90 (0.85-0.94) |\n",
      "| Radiomics  |      0.828 |     0.966 |    0.977 | 0.959 | 0.713 | 0.0408 | 0.82 (0.78-0.86) | 0.73 (0.67-0.78) | 0.96 (0.91-0.98) |\n",
      "\n",
      "##### Validation\n",
      "\n",
      "| Modality   |   F1 Score |   ROC AUC |   PR AUC |   PPV |   NPV |   FDR | Acc (95% CI)     | TPR (95% CI)     | TNR (95% CI)     |\n",
      "|:-----------|-----------:|----------:|---------:|------:|------:|------:|:-----------------|:-----------------|:-----------------|\n",
      "| Clinical   |      0.739 |     0.487 |    0.556 | 0.607 | 0.636 | 0.393 | 0.61 (0.52-0.69) | 0.94 (0.86-0.98) | 0.14 (0.06-0.26) |\n",
      "| T2         |      0.792 |     0.769 |    0.820 | 0.766 | 0.717 | 0.234 | 0.75 (0.66-0.82) | 0.82 (0.71-0.89) | 0.65 (0.51-0.76) |\n",
      "| T1         |      0.798 |     0.696 |    0.731 | 0.714 | 0.781 | 0.286 | 0.73 (0.65-0.80) | 0.90 (0.81-0.95) | 0.49 (0.36-0.62) |\n",
      "| Ensemble   |      0.819 |     0.780 |    0.826 | 0.723 | 0.862 | 0.277 | 0.76 (0.67-0.82) | 0.94 (0.86-0.98) | 0.49 (0.36-0.62) |\n",
      "| Expert 1   |      0.756 |   N/A     |  N/A     | 0.630 | 0.733 | 0.370 | 0.64 (0.55-0.72) | 0.94 (0.86-0.98) | 0.22 (0.12-0.35) |\n",
      "| Expert 2   |      0.773 |   N/A     |  N/A     | 0.654 | 0.789 | 0.346 | 0.67 (0.59-0.75) | 0.94 (0.86-0.98) | 0.29 (0.19-0.43) |\n",
      "| Radiomics  |      0.770 |     0.806 |    0.847 | 0.825 | 0.667 | 0.175 | 0.75 (0.66-0.82) | 0.72 (0.61-0.81) | 0.78 (0.65-0.88) |\n",
      "\n",
      "##### Test\n",
      "\n",
      "| Modality   |   F1 Score |   ROC AUC |   PR AUC |   PPV |   NPV |   FDR | Acc (95% CI)     | TPR (95% CI)     | TNR (95% CI)     |\n",
      "|:-----------|-----------:|----------:|---------:|------:|------:|------:|:-----------------|:-----------------|:-----------------|\n",
      "| Clinical   |       0.76 |      0.52 |     0.63 |  0.62 |  0.80 |  0.38 | 0.63 (0.51-0.74) | 0.97 (0.85-1.00) | 0.15 (0.06-0.34) |\n",
      "| T2         |       0.78 |      0.71 |     0.69 |  0.75 |  0.70 |  0.25 | 0.73 (0.61-0.82) | 0.81 (0.65-0.91) | 0.62 (0.42-0.78) |\n",
      "| T1         |       0.79 |      0.69 |     0.78 |  0.69 |  0.79 |  0.31 | 0.71 (0.59-0.81) | 0.92 (0.78-0.98) | 0.42 (0.26-0.61) |\n",
      "| Ensemble   |       0.80 |      0.77 |     0.77 |  0.71 |  0.80 |  0.29 | 0.73 (0.61-0.82) | 0.92 (0.78-0.98) | 0.46 (0.29-0.65) |\n",
      "| Expert 1   |       0.79 |    N/A    |   N/A    |  0.65 |  1.0  |  0.35 | 0.68 (0.56-0.78) | 1.00 (0.89-1.00) | 0.23 (0.11-0.42) |\n",
      "| Expert 2   |       0.78 |    N/A    |   N/A    |  0.66 |  0.80 |  0.34 | 0.68 (0.56-0.78) | 0.95 (0.81-0.99) | 0.31 (0.16-0.50) |\n",
      "| Expert 3   |       0.83 |    N/A    |   N/A    |  0.86 |  0.75 |  0.14 | 0.81 (0.69-0.89) | 0.81 (0.65-0.91) | 0.81 (0.62-0.92) |\n",
      "| Expert 4   |       0.91 |    N/A    |   N/A    |  0.89 |  0.88 |  0.11 | 0.89 (0.79-0.95) | 0.92 (0.78-0.98) | 0.85 (0.66-0.94) |\n",
      "| Radiomics  |       0.78 |      0.81 |     0.83 |  0.80 |  0.68 |  0.20 | 0.75 (0.63-0.84) | 0.76 (0.60-0.87) | 0.73 (0.54-0.87) |\n"
     ]
    }
   ],
   "source": [
    "expert_features = all_features(files = [config.EXPERTS])\n",
    "comparison_model_features = all_features(files=[\"features/comparison-models.csv\"])\n",
    "df = get_statistics(train, get_experts_for_names(expert_features, train_set.names), get_experts_for_names(comparison_model_features, train_set.names, experts=[\"radiomics\"], transform=float))\n",
    "df = df.drop(['Acc', \"TPR\", \"TNR\", \"Total\", \"Malignant\", \"Benign\"], axis=1)\n",
    "print()\n",
    "print(\"##### Train\")\n",
    "print()\n",
    "print(tabulate(df, tablefmt=\"pipe\", headers=\"keys\", floatfmt=\"#.3g\").replace(\"nan\", \"N/A\").replace(\"Features\", \"Clinical\"))\n",
    "df = get_statistics(validation, get_experts_for_names(expert_features, validation_set.names), get_experts_for_names(comparison_model_features, validation_set.names, experts=[\"radiomics\"], transform=float))\n",
    "df = df.drop(['Acc', \"TPR\", \"TNR\", \"Total\", \"Malignant\", \"Benign\"], axis=1)\n",
    "print()\n",
    "print(\"##### Validation\")\n",
    "print()\n",
    "print(tabulate(df, tablefmt=\"pipe\", headers=\"keys\", floatfmt=\"#.3g\").replace(\"nan\", \"N/A\").replace(\"Features\", \"Clinical\"))\n",
    "df = get_statistics(test, get_experts_for_names(expert_features, test_set.names, experts=[\"expert1\", \"expert2\", \"expert3\", \"expert4\"]), get_experts_for_names(comparison_model_features, test_set.names, experts=[\"radiomics\"], transform=float))\n",
    "test_statistics = df\n",
    "df = df.drop(['Acc', \"TPR\", \"TNR\", \"Total\", \"Malignant\", \"Benign\"], axis=1)\n",
    "print()\n",
    "print(\"##### Test\")\n",
    "print()\n",
    "print(tabulate(df, tablefmt=\"pipe\", headers=\"keys\", floatfmt=\"#.2g\").replace(\"nan\", \"N/A\").replace(\"Features\", \"Clinical\"))\n",
    "#df = get_statistics(test_1, get_experts_for_names(expert_features, test_set.names, experts=[\"expert1\", \"expert2\", \"expert3\", \"expert4\"]), get_experts_for_names(comparison_model_features, test_set.names, experts=[\"radiomics\"], transform=float))\n",
    "#test_1_statistics = df\n",
    "#df = df.drop(['Acc', \"TPR\", \"TNR\", \"Total\", \"Malignant\", \"Benign\"], axis=1)\n",
    "#print()\n",
    "#print(\"##### Test 1\")\n",
    "#print()\n",
    "#print(tabulate(df, tablefmt=\"pipe\", headers=\"keys\", floatfmt=\"#.2g\").replace(\"nan\", \"N/A\").replace(\"Features\", \"Clinical\"))\n",
    "#df = get_statistics(test_2, get_experts_for_names(expert_features, test_set.names, experts=[\"expert1\", \"expert2\", \"expert3\", \"expert4\"]), get_experts_for_names(comparison_model_features, test_set.names, experts=[\"radiomics\"], transform=float))\n",
    "#test_2_statistics = df\n",
    "#df = df.drop(['Acc', \"TPR\", \"TNR\", \"Total\", \"Malignant\", \"Benign\"], axis=1)\n",
    "#print()\n",
    "#print(\"##### Test 2\")\n",
    "#print()\n",
    "#print(tabulate(df, tablefmt=\"pipe\", headers=\"keys\", floatfmt=\"#.2g\").replace(\"nan\", \"N/A\").replace(\"Features\", \"Clinical\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_statistics = {\n",
    " 'F1 Score': 0.88,\n",
    " 'ROC AUC': 0.6243243243243244,\n",
    " 'PR AUC': 0.90,\n",
    " 'Acc': 0.80,\n",
    " 'TPR': 0.96,\n",
    " 'TNR': 0.22,\n",
    " 'PPV': 0.896551724137931,\n",
    " 'NPV': 0.3888888888888889,\n",
    " 'FDR': 0.10344827586206896,\n",
    " 'Total': 47,\n",
    " 'Malignant': 37,\n",
    " 'Benign': 10,\n",
    " 'Acc (95% CI)': '0.70 (0.56-0.81)',\n",
    " 'TPR (95% CI)': '0.70 (0.54-0.83)',\n",
    " 'TNR (95% CI)': '0.70 (0.39-0.90)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_1_statistics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-de514bd6d83b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mt2_statistics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_AUC_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_statistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"T2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mensemble_statistics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_AUC_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_statistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Ensemble\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mensemble_1_statistics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_AUC_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_1_statistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Ensemble\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mensemble_2_statistics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_AUC_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_2_statistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Ensemble\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mcross_validation_statistics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_AUC_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_validation_statistics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_1_statistics' is not defined"
     ]
    }
   ],
   "source": [
    "CI_text = \"\"\"{value:.2g} (95% CI: {low:.2g}-{high:.2g})\"\"\"\n",
    "\n",
    "statistics_text = \"\"\"test accuracy of {accuracy}, F1 score of {f1:.2g}, and sensitivity of {sensitivity}, and specificity of {specificity}\"\"\"\n",
    "def format_statistics(data):\n",
    "    acc_low, acc_high = adjusted_wald(data[\"Acc\"], data[\"Total\"])\n",
    "    tpr_low, tpr_high = adjusted_wald(data[\"TPR\"], data[\"Malignant\"])\n",
    "    tnr_low, tnr_high = adjusted_wald(data[\"TNR\"], data[\"Benign\"])\n",
    "    data_dict = {\n",
    "        \"accuracy\": CI_text.format(value=data[\"Acc\"], low=acc_low, high=acc_high),\n",
    "        \"sensitivity\": CI_text.format(value=data[\"TPR\"], low=tpr_low, high=tpr_high),\n",
    "        \"specificity\": CI_text.format(value=data[\"TNR\"], low=tnr_low, high=tnr_high),\n",
    "        \"f1\": data[\"F1 Score\"],\n",
    "    }\n",
    "    return statistics_text.format(**data_dict)\n",
    "\n",
    "statistics_AUC_text = \"\"\"test accuracy of {accuracy}, F1 score of {f1:.2g}, precision recall AUC of {PR_AUC:.2g}, sensitivity of {sensitivity}, and specificity of {specificity}\"\"\"\n",
    "def format_AUC_statistics(data):\n",
    "    acc_low, acc_high = adjusted_wald(data[\"Acc\"], data[\"Total\"])\n",
    "    tpr_low, tpr_high = adjusted_wald(data[\"TPR\"], data[\"Malignant\"])\n",
    "    tnr_low, tnr_high = adjusted_wald(data[\"TNR\"], data[\"Benign\"])\n",
    "    data_dict = {\n",
    "        \"accuracy\": CI_text.format(value=data[\"Acc\"], low=acc_low, high=acc_high),\n",
    "        \"sensitivity\": CI_text.format(value=data[\"TPR\"], low=tpr_low, high=tpr_high),\n",
    "        \"specificity\": CI_text.format(value=data[\"TNR\"], low=tnr_low, high=tnr_high),\n",
    "        \"f1\": data[\"F1 Score\"],\n",
    "        \"PR_AUC\": data[\"PR AUC\"],\n",
    "    }\n",
    "    return statistics_AUC_text.format(**data_dict)\n",
    "\n",
    "comparison_text =\"\"\"{accuracy_judge} test accuracy ({accuracy_1:.2g} vs. {accuracy_2:.2g}, p={accuracy_p:.2g}), {sensitivity_judge} test sensitivity ({sensitivity_1:.2g} vs. {sensitivity_2:.2g}, p={sensitivity_p:.2g}) and {specificity_judge} test specificity ({specificity_1:.2g} vs. {specificity_2:.2g}, p={specificity_p:.2g})\"\"\"\n",
    "def format_comparison_text(data_1, data_2):\n",
    "    data_dict = {\n",
    "        \"accuracy_judge\": \"higher\" if data_1[\"Acc\"] > data_2[\"Acc\"] else \"lower\",\n",
    "        \"sensitivity_judge\": \"higher\" if data_1[\"TPR\"] > data_2[\"TPR\"] else \"lower\",\n",
    "        \"specificity_judge\": \"higher\" if data_1[\"TNR\"] > data_2[\"TNR\"] else \"lower\",\n",
    "        \"accuracy_1\": data_1[\"Acc\"],\n",
    "        \"specificity_1\": data_1[\"TNR\"],\n",
    "        \"sensitivity_1\": data_1[\"TPR\"],\n",
    "        \"accuracy_2\": data_2[\"Acc\"],\n",
    "        \"specificity_2\": data_2[\"TNR\"],\n",
    "        \"sensitivity_2\": data_2[\"TPR\"],\n",
    "        \"accuracy_p\": binom_test(int(data_1[\"Acc\"] * data_1[\"Total\"]), data_1[\"Total\"], data_2[\"Acc\"]),\n",
    "        \"specificity_p\": binom_test(int(data_1[\"TNR\"] * data_1[\"Benign\"]), data_1[\"Benign\"], data_2[\"TNR\"]),\n",
    "        \"sensitivity_p\": binom_test(int(data_1[\"TPR\"] * data_1[\"Malignant\"]), data_1[\"Malignant\"], data_2[\"TPR\"]),\n",
    "    }\n",
    "    return comparison_text.format(**data_dict)\n",
    "\n",
    "results_text = \"\"\"\n",
    "## Model performance\n",
    "The train, validation and test sets were balanced in terms of age, gender, tumor size, tumor laterality, tumor location, histologic diagnosis, and institution (Supplemental table S1).\n",
    "\n",
    "Performance characteristics of the clinical variable logistic regression, models trained on T1C and T2WI images, and the final ensemble model in test set are summarized in Table 2. Performance characteristics in training and validation sets are summarized in Supplemental table S2. The clinical variable logistic regression achieved a {logistic_regression_statistics}.\n",
    "\n",
    "The T1C trained model achieved a {t1_statistics}. The T2WI trained model achieved a {t2_statistics}. The ensemble model achieved a {ensemble_statistics}. The ensemble model achieved comparative performance on the second set of test set segmentations with a {ensemble_1_statistics} and the third set of test set segmentation with a {ensemble_2_statistics} (Supplemental table S3). On average, cross validation analysis of the ensemble model demonstrated a {cross_validation_statistics}. Supplemental table S4 summarizes the cross-validation performance of the ensemble model.\n",
    "\n",
    "In comparison, expert 1 achieved a {expert_1_statistics}; expert 2 had a {expert_2_statistics}; expert 3 had a {expert_3_statistics}; expert 4 had a {expert_4_statistics}. Radiomics model achieved a {radiomics_statistics} (Supplemental table S5).\n",
    "\n",
    "CONFIRM THE BELOW PARAGRAPH IS STILL TRUE\n",
    "\n",
    "Compared to all experts averaged, the ensemble deep learning model had {ensemble_vs_experts}, COMMENT although none of these statistics was significantly different. Compared to the radiomics model, the ensemble deep learning model had {ensemble_vs_radiomics}; COMMENT difference in accuracy was not significant but differences in sensitivity and specificity between radiomics and ensemble deep learning models were significant. Compared to all experts averaged, the radiomics model had {radiomics_vs_experts}; COMMENT difference in accuracy was not significant, but differences in sensitivity and specificity between radiomics and averaged expert performance metrics were significant. Figure 2 shows the precision recall curves of all models overlaid with expert performance.\n",
    "\n",
    "Grad-Cam focus maps demonstrate that for the correctly classified images by our model, the algorithm was more likely to focus on the lesion or part of the lesion deemed important by the radiologists, while focus was more likely to be on the surrounding tissue for the incorrectly classified lesions (Figure 3). t-SNE representation of the final dense layer of ResNet demonstrates good separation of malignant and benign lesions by the model when compared to histopathological diagnosis (Figure 4).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(results_text.format(\n",
    "    logistic_regression_statistics=format_AUC_statistics(dict(test_statistics.loc[\"Features\"])),\n",
    "    t1_statistics=format_AUC_statistics(dict(test_statistics.loc[\"T1\"])),\n",
    "    t2_statistics=format_AUC_statistics(dict(test_statistics.loc[\"T2\"])),\n",
    "    ensemble_statistics=format_AUC_statistics(dict(test_statistics.loc[\"Ensemble\"])),\n",
    "    ensemble_1_statistics=format_AUC_statistics(dict(test_1_statistics.loc[\"Ensemble\"])),\n",
    "    ensemble_2_statistics=format_AUC_statistics(dict(test_2_statistics.loc[\"Ensemble\"])),\n",
    "    cross_validation_statistics=format_AUC_statistics(cross_validation_statistics),\n",
    "    expert_1_statistics=format_statistics(dict(test_statistics.loc[\"Expert 1\"])),\n",
    "    expert_2_statistics=format_statistics(dict(test_statistics.loc[\"Expert 2\"])),\n",
    "    expert_3_statistics=format_statistics(dict(test_statistics.loc[\"Expert 3\"])),\n",
    "    expert_4_statistics=format_statistics(dict(test_statistics.loc[\"Expert 4\"])),\n",
    "    radiomics_statistics=format_statistics(dict(test_statistics.loc[\"Radiomics\"])),\n",
    "    ensemble_vs_experts=format_comparison_text(dict(test_statistics.loc[\"Ensemble\"]), dict(test_statistics.loc[[\"Expert 1\", \"Expert 2\", \"Expert 3\", \"Expert 4\"]].mean())),\n",
    "    ensemble_vs_radiomics=format_comparison_text(dict(test_statistics.loc[\"Ensemble\"]), dict(test_statistics.loc[\"Radiomics\"])),\n",
    "    radiomics_vs_experts=format_comparison_text(dict(test_statistics.loc[\"Radiomics\"]), dict(test_statistics.loc[[\"Expert 1\", \"Expert 2\", \"Expert 3\", \"Expert 4\"]].mean())),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_text = \"\"\"\n",
    "## Inter-segmenter agreement\n",
    "\n",
    "The average DSC among our three segmenters was {dice_average}. Segmenter 1 and 2 had an average DSC of {dice_1_2}. Segmenter 2 and 3 had an average DSC of {dice_2_3}. Segmenter 1 and 3 had an average DSC of {dice_1_3}. Benign lesions had an average DSC of {dice_benign} across all reviewers, while malignant lesions had an average DSC of {dice_malignant} across all reviewers. \n",
    "\n",
    "## Model performance\n",
    "The train, validation and test sets were balanced in terms of age, gender, tumor size, tumor laterality, tumor location, histologic diagnosis, and institution (Supplemental table S1). \n",
    "\n",
    "Performance characteristics of the clinical variable logistic regression, models trained on T1C and T2WI images, and the final ensemble model in test set are summarized in Table 2. Performance characteristics in training and validation sets are summarized in Supplemental table S2. The clinical variable logistic regression achieved a test accuracy of {regression_accuracy}, F1 score of {regression_F1}, precision recall AUC of {regression_PR_AUC}, sensitivity of {regression_sensitivity}, and specificity of {regression_specificity}. \n",
    "\n",
    "The T1C trained model achieved a test accuracy of {t1c_accuracy}, F1 score of {t1c_f1}, precision recall AUC of {t1c_PR_AUC}, sensitivity of 0.92 (95% CI: 0.78-0.98), and specificity of 0.50 (95% CI: 0.24-0.76). The T2WI trained model achieved a test accuracy of 0.83 (95% CI: 0.70-0.91), F1 score of 0.90, precision recall AUC of 0.92, sensitivity of 0.97 (95% CI: 0.84-1.00), and specificity of 0.30 (95% CI: 0.10-0.61). The ensemble model achieved a test accuracy of 0.89 (95% CI: 0.77-0.96), F1 score of 0.94, precision recall AUC of 0.90, sensitivity of 1.0 (95% CI: 0.88-1.00), and specificity of 0.50 (95% CI: 0.24-0.76). The ensemble model achieved comparative performance on the second set of test set segmentations with an accuracy of 0.81 (95% CI: 0.67-0.90), F1 score of 0.89, precision recall AUC of 0.89, sensitivity of 0.97 (95% CI: 0.84-1.00), and specificity of 0.20 (95% CI: 0.05-0.52) and the third set of test set segmentation with an accuracy of 0.81 (95% CI: 0.67-0.90), F1 score of 0.89, precision recall AUC of 0.83, sensitivity of 1.0 (95% CI: 0.88-1.00), and specificity of 0.10 (95% CI: 0.00-0.42) (Supplemental table S3). The average cross validation test accuracy was 0.80 (95% CI: 0.66-0.89) with average F1 score of 0.88, precision recall AUC of 0.90, sensitivity of 0.96 (95% CI: 0.83-1.00), and specificity of 0.22 (95% CI: 0.06-0.54). Supplemental table S4 summarizes the cross-validation performance of the ensemble model.\n",
    "\n",
    "In comparison, expert 1 achieved a test accuracy of 0.85 (95% CI: 0.72-0.92), F1 score of 0.91, and sensitivity of 1.0 (95% CI: 0.88-1.00), and specificity of 0.30 (95% CI: 0.10-0.61); expert 2 had a test accuracy of 0.79 (95% CI: 0.65-0.88), F1 score of 0.88, and sensitivity of 0.95 (95% CI: 0.82-1.00), and specificity of 0.20 (95% CI: 0.05-0.52); expert 3 had a test accuracy of 0.74 (95% CI: 0.60-0.84), F1 score of 0.73, sensitivity of 0.81 (95% CI: 0.65-0.90), and specificity of 0.50 (95% CI: 0.24-0.76); expert 4 had a test accuracy of 0.85 (95% CI: 0.72-0.93), F1 score of 0.91, and sensitivity of 0.92 (95% CI: 0.78 -0.98), and specificity of 0.60 (95% CI: 0.31-0.83). Radiomics model achieved a test accuracy of 0.78 (95% CI: 0.64-0.88), F1 score of 0.84, sensitivity of 0.76 (95% CI: 0.60-0.87), and specificity of 0.80 (95% CI: 0.47-0.95) (Supplemental table S5).\n",
    "\n",
    "Compared to all experts averaged, the ensemble deep learning model had higher test accuracy (0.89 vs. 0.81, p=0.32), higher test sensitivity (1.00 vs. 0.92, p=0.07) and higher test specificity (0.50 vs. 0.40, p=0.53), although none of these statistics was significantly different. Compared to the radiomics model, the ensemble deep learning model had higher test accuracy (0.89 vs. 0.77, p=0.12), higher test sensitivity (1.00 vs. 0.76, p<0.01) and lower test specificity (0.50 vs. 0.80, p=0.03); difference in accuracy was not significant but differences in sensitivity and specificity between radiomics and ensemble deep learning models were significant. Compared to all experts averaged, the radiomics model had lower test accuracy (0.77 vs. 0.81, p=0.61), lower test sensitivity (0.76 vs. 0.92, p=0.0021) and higher test specificity (0.80 vs. 0.40, p<0.01); difference in accuracy was not significant, but differences in sensitivity and specificity between radiomics and averaged expert performance metrics were significant. Figure 2 shows the precision recall curves of all models overlaid with expert performance. \n",
    "\n",
    "Grad-Cam focus maps demonstrate that for the correctly classified images by our model, the algorithm was more likely to focus on the lesion or part of the lesion deemed important by the radiologists, while focus was more likely to be on the surrounding tissue for the incorrectly classified lesions (Figure 3). t-SNE representation of the final dense layer of ResNet demonstrates good separation of malignant and benign lesions by the model when compared to histopathological diagnosis (Figure 4).\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plot_multiple_precision_recall(train, experts=get_experts_for_names(expert_features, train_set.names))#, comparison_models=get_experts_for_names(comparison_model_features, train_set.names, experts=['radiomics'], transform=float))\n",
    "fig.savefig(\"figures/combined-train-precision-recall.svg\", bbox_inches = \"tight\")\n",
    "fig = plot_multiple_precision_recall(validation, experts=get_experts_for_names(expert_features, validation_set.names))#,  comparison_models=get_experts_for_names(comparison_model_features, validation_set.names, experts=['radiomics'], transform=float))\n",
    "fig.savefig(\"figures/combined-validation-precision-recall.svg\", bbox_inches = \"tight\")\n",
    "fig = plot_multiple_precision_recall(test, experts=get_experts_for_names(expert_features, test_set.names, experts=[\"expert1\", \"expert2\", \"expert3\", \"expert4\"]))#, comparison_models=get_experts_for_names(comparison_model_features, test_set.names, experts=['radiomics'], transform=float))\n",
    "fig.savefig(\"figures/combined-test-precision-recall.svg\", bbox_inches = \"tight\")\n",
    "fig = plot_multiple_precision_recall(test_1, experts=get_experts_for_names(expert_features, test_set.names, experts=[\"expert1\", \"expert2\", \"expert3\", \"expert4\"]))#, comparison_models=get_experts_for_names(comparison_model_features, test_set.names, experts=['radiomics'], transform=float))\n",
    "fig.savefig(\"figures/combined-test-1-precision-recall.svg\", bbox_inches = \"tight\")\n",
    "fig = plot_multiple_precision_recall(test_2, experts=get_experts_for_names(expert_features, test_set.names, experts=[\"expert1\", \"expert2\", \"expert3\", \"expert4\"]))#, comparison_models=get_experts_for_names(comparison_model_features, test_set.names, experts=['radiomics'], transform=float))\n",
    "fig.savefig(\"figures/combined-test-2-precision-recall.svg\", bbox_inches = \"tight\")\n",
    "fig = plot_multiple_roc_curve(train, experts=get_experts_for_names(expert_features, train_set.names))#, comparison_models=get_experts_for_names(comparison_model_features, train_set.names, experts=['radiomics'], transform=float))\n",
    "fig.savefig(\"figures/combined-train-roc.svg\", bbox_inches = \"tight\")\n",
    "fig = plot_multiple_roc_curve(validation, experts=get_experts_for_names(expert_features, validation_set.names))#, comparison_models=get_experts_for_names(comparison_model_features, validation_set.names, experts=['radiomics'], transform=float))\n",
    "fig.savefig(\"figures/combined-validation-roc.svg\", bbox_inches = \"tight\")\n",
    "fig = plot_multiple_roc_curve(test, experts=get_experts_for_names(expert_features, test_set.names, experts=[\"expert1\", \"expert2\", \"expert3\", \"expert4\"]))#, comparison_models=get_experts_for_names(comparison_model_features, test_set.names, experts=['radiomics'], transform=float))\n",
    "fig.savefig(\"figures/combined-test-roc.svg\", bbox_inches = \"tight\")\n",
    "fig = plot_multiple_roc_curve(test_1, experts=get_experts_for_names(expert_features, test_set.names, experts=[\"expert1\", \"expert2\", \"expert3\", \"expert4\"]))#, comparison_models=get_experts_for_names(comparison_model_features, test_set.names, experts=['radiomics'], transform=float))\n",
    "fig.savefig(\"figures/combined-test-1-roc.svg\", bbox_inches = \"tight\")\n",
    "fig = plot_multiple_roc_curve(test_2, experts=get_experts_for_names(expert_features, test_set.names, experts=[\"expert1\", \"expert2\", \"expert3\", \"expert4\"]))#, comparison_models=get_experts_for_names(comparison_model_features, test_set.names, experts=['radiomics'], transform=float))\n",
    "fig.savefig(\"figures/combined-test-2-roc.svg\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_num_for_modality(dataset, experts=[], comparison_models=[]): \n",
    "    results = list()\n",
    "    if len(experts) > 0:\n",
    "        for i, expert in enumerate(experts): \n",
    "            labels = dataset[\"t1-labels\"]\n",
    "            predictions = expert\n",
    "            correct = sum([ labels[i] == p for i, p in enumerate(predictions) ])\n",
    "            total = len(labels)\n",
    "            results.append({ \n",
    "                \"correct\": correct, \n",
    "                \"total\": total, \n",
    "                \"incorrect\": total-correct, \n",
    "                \"modality\": \"Expert {}\".format(i),\n",
    "                \"acc\": correct/total,                \n",
    "                \"wald\": adjusted_wald(correct/total, total),\n",
    "                **calculate_confusion_matrix_stats_predictions(labels, predictions),\n",
    "            })\n",
    "    for modality in MODALITIES: \n",
    "        labels = dataset[\"{}-labels\".format(modality)]\n",
    "        probabilities = dataset[\"{}-probabilities\".format(modality)]\n",
    "        predictions = dataset[\"{}-predictions\".format(modality)]\n",
    "        total = len(labels)\n",
    "        correct = sum([ labels[i] == p for i, p in enumerate(predictions) ])\n",
    "        results.append({ \n",
    "            \"correct\": correct, \n",
    "            \"total\": total, \n",
    "            \"incorrect\": total-correct, \n",
    "            \"modality\": MODALITY_KEY[modality],\n",
    "            \"acc\": correct/total,\n",
    "            \"wald\": adjusted_wald(correct/total, total),\n",
    "            **calculate_confusion_matrix_stats_predictions(labels, predictions),            \n",
    "        })        \n",
    "    for probabilities in comparison_models: \n",
    "        modality = \"Radiomics\"\n",
    "        labels = dataset[\"t1-labels\"]\n",
    "        predictions = [p > 0.5 for p in probabilities]\n",
    "        predictions = dataset[\"{}-predictions\".format(modality)]\n",
    "        total = len(labels)\n",
    "        correct = sum([ labels[i] == p for i, p in enumerate(predictions) ])\n",
    "        results.append({ \n",
    "            \"correct\": correct, \n",
    "            \"total\": total, \n",
    "            \"incorrect\": total-correct, \n",
    "            \"modality\": modality,\n",
    "            \"acc\": correct/total,\n",
    "            \"wald\": adjusted_wald(correct/total, total),\n",
    "            **calculate_confusion_matrix_stats_predictions(labels, predictions),            \n",
    "        })                \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = correct_num_for_modality(test, experts=get_experts_for_names(expert_features, test_set.names, experts=[\"expert1\", \"expert2\", \"expert3\", \"expert4\"]))#, comparison_models=get_experts_for_names(comparison_model_features, test_set.names, experts=['radiomics'], transform=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "experts = get_experts_for_names(expert_features, test_set.names, experts=[\"expert1\", \"expert2\", \"expert3\", \"expert4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa_scores = list()\n",
    "for e in experts: \n",
    "    current = list()\n",
    "    for x in experts: \n",
    "        current.append(cohen_kappa_score(e, x))\n",
    "    kappa_scores.append(current)\n",
    "kappa_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.heatmap(kappa_scores, annot=True, square=True, fmt=\".2f\", xticklabels=[\"1\", \"2\", \"3\", \"4\"], yticklabels=[\"1\", \"2\", \"3\", \"4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_kappa = list()\n",
    "for x, y in combinations(experts, 2): \n",
    "    unique_kappa.append(cohen_kappa_score(x, y))\n",
    "np.average(unique_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fleiss_kappa(ratings, n):\n",
    "    '''\n",
    "    Computes the Fleiss' kappa measure for assessing the reliability of \n",
    "    agreement between a fixed number n of raters when assigning categorical\n",
    "    ratings to a number of items.\n",
    "    \n",
    "    Args:\n",
    "        ratings: a list of (item, category)-ratings\n",
    "        n: number of raters\n",
    "        k: number of categories\n",
    "    Returns:\n",
    "        the Fleiss' kappa score\n",
    "    \n",
    "    See also:\n",
    "        http://en.wikipedia.org/wiki/Fleiss'_kappa\n",
    "    '''\n",
    "    items = set()\n",
    "    categories = set()\n",
    "    n_ij = {}\n",
    "    \n",
    "    for i, c in ratings:\n",
    "        items.add(i)\n",
    "        categories.add(c)\n",
    "        n_ij[(i,c)] = n_ij.get((i,c), 0) + 1\n",
    "    \n",
    "    N = len(items)\n",
    "    \n",
    "    p_j = dict(((c, sum(n_ij.get((i, c), 0) for i in items) / (1.0 * n * N)) for c in categories))\n",
    "    P_i = dict(((i, (sum(n_ij.get((i, c), 0) ** 2 for c in categories) - n) / (n * (n - 1.0))) for i in items))\n",
    "\n",
    "    P_bar = sum(P_i.values()) / (1.0 * N)\n",
    "    P_e_bar = sum(value ** 2 for value in p_j.values())\n",
    "    \n",
    "    kappa = (P_bar - P_e_bar) / (1 - P_e_bar)\n",
    "    \n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fleiss_kappa_array = list()\n",
    "for e in list(zip(*experts)): \n",
    "    for i in e: \n",
    "        fleiss_kappa_array.append((1, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fleiss_kappa(fleiss_kappa_array, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = [(1, 'yes')] * 10 + [(1, 'no')] * 0  + \\\n",
    "[(2, 'yes')] * 8  + [(2, 'no')] * 2  + \\\n",
    "[(3, 'yes')] * 9  + [(3, 'no')] * 1  + \\\n",
    "[(4, 'yes')] * 0  + [(4, 'no')] * 10 + \\\n",
    "[(5, 'yes')] * 7  + [(5, 'no')] * 3\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(experts).T\n",
    "fleiss_kappa(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = results.pop()\n",
    "for r in results: \n",
    "    print(r[\"modality\"], fisher_exact([[ensemble[\"correct\"], r[\"correct\"]], [ensemble[\"incorrect\"], r[\"incorrect\"]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
