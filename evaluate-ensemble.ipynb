{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config\n",
    "import pandas\n",
    "import seaborn\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import papermill as pm\n",
    "from stacked_data import stacked_data\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import ExtraTreesClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier, IsolationForest, RandomForestClassifier, VotingClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from evaluate import calculate_confusion_matrix_stats, plot_roc_curve, plot_precision_recall, plot_confusion_matrix_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "MODELS = [\n",
    "    \"9adb8e80-457c-4419-8b01-92325ba99fc3\", # t1\n",
    "    \"dce56921-62a8-40f3-8cce-73b06d2b049c\", # features\n",
    "    \"391b0942-7801-4184-b551-2b62fe269c58\", # t2 \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = MODELS\n",
    "print(\"models: {}\".format(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sd = stacked_data(uuids=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.array(list(zip(*sd[0])))\n",
    "validation_set = np.array(list(zip(*sd[1])))\n",
    "test_set = np.array(list(zip(*sd[2])))\n",
    "train_labels = np.array(sd[3])\n",
    "validation_labels = np.array(sd[4])\n",
    "test_labels = np.array(sd[5])\n",
    "train_fix_set = np.array(list(zip(*sd[6])))\n",
    "train_fix_labels = np.array(sd[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIERS = [\n",
    "    #ExtraTreesClassifier,\n",
    "    #AdaBoostClassifier, \n",
    "    BaggingClassifier, \n",
    "    #GradientBoostingClassifier, \n",
    "    #RandomForestClassifier, \n",
    "]\n",
    "PARAMETERS = [\n",
    "    dict(n_estimators=20, max_samples=0.1, max_features=1),\n",
    "    dict(max_leaf_nodes=5, max_depth=2), \n",
    "    dict(),     \n",
    "    dict(),     \n",
    "    dict(),     \n",
    "    dict(),     \n",
    "    dict(),     \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "best_model = None\n",
    "for j, c in enumerate(CLASSIFIERS): \n",
    "    model_best = 0\n",
    "    model_acc = 0\n",
    "    for i in tqdm(range(1000)): \n",
    "        clf = c(random_state=i, **(PARAMETERS[j]))\n",
    "        clf.fit(train_set, train_labels)\n",
    "        score = clf.score(validation_set, validation_labels)\n",
    "        if score > best_acc:\n",
    "            best_acc = score\n",
    "            best_model = clf\n",
    "        if score > model_acc:\n",
    "            model_acc = score\n",
    "            model_best = clf\n",
    "    print(model_acc)\n",
    "    print(model_best)\n",
    "    print(best_acc)\n",
    "    print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"train accuracy: {}\".format(best_model.score(train_fix_set, train_fix_labels)))\n",
    "print(\"validation accuracy: {}\".format(best_model.score(validation_set, validation_labels)))\n",
    "print(\"test accuracy: {}\".format(best_model.score(test_set, test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_model\n",
    "predictions = model.predict(train_fix_set)\n",
    "probabilities = model.predict_proba(train_fix_set)\n",
    "pm.record(\"train_labels\", list(train_fix_labels))\n",
    "pm.record(\"train_probabilities\", list(probabilities[:,1]))\n",
    "pm.record(\"train_predictions\", list(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy: {}\".format(metrics.accuracy_score(train_fix_labels, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_confusion_matrix_ensemble(train_fix_labels, predictions, [\"benign\", \"malignant\"])\n",
    "fig.savefig(\"figures/ensemble-train-confusion-matrix.svg\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pandas.DataFrame(calculate_confusion_matrix_stats(train_fix_labels, probabilities[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plot_roc_curve(train_fix_labels, probabilities[:,1])\n",
    "fig.savefig(\"figures/ensemble-train-roc-curve.svg\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plot_precision_recall(train_fix_labels, probabilities[:,1])\n",
    "fig.savefig(\"figures/ensemble-train-precisionrecall.svg\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_model\n",
    "predictions = model.predict(validation_set)\n",
    "probabilities = model.predict_proba(validation_set)\n",
    "pm.record(\"validation_labels\", list(validation_labels))\n",
    "pm.record(\"validation_probabilities\", list(probabilities[:,1]))\n",
    "pm.record(\"validation_predictions\", list(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy: {}\".format(metrics.accuracy_score(validation_labels, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_confusion_matrix_ensemble(validation_labels, predictions, [\"benign\", \"malignant\"])\n",
    "fig.savefig(\"figures/ensemble-validation-confusion-matrix.svg\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pandas.DataFrame(calculate_confusion_matrix_stats(validation_labels, probabilities[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plot_roc_curve(validation_labels, probabilities[:,1])\n",
    "fig.savefig(\"figures/ensemble-validation-roc-curve.svg\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plot_precision_recall(validation_labels, probabilities[:,1])\n",
    "fig.savefig(\"figures/ensemble-validation-precisionrecall.svg\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_model\n",
    "predictions = model.predict(test_set)\n",
    "probabilities = model.predict_proba(test_set)\n",
    "pm.record(\"test_labels\", list(test_labels))\n",
    "pm.record(\"test_probabilities\", list(probabilities[:,1]))\n",
    "pm.record(\"test_predictions\", list(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy: {}\".format(metrics.accuracy_score(test_labels, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_confusion_matrix_ensemble(test_labels, predictions, [\"benign\", \"malignant\"])\n",
    "fig.savefig(\"figures/ensemble-test-confusion-matrix.svg\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pandas.DataFrame(calculate_confusion_matrix_stats(test_labels, probabilities[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plot_roc_curve(test_labels, probabilities[:,1])\n",
    "fig.savefig(\"figures/ensemble-test-roc-curve.svg\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plot_precision_recall(test_labels, probabilities[:,1])\n",
    "fig.savefig(\"figures/ensemble-test-precisionrecall.svg\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "The raw code for this IPython notebook is by default hidden for easier reading.\n",
       "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>."
      ],
      "text/plain": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "The raw code for this IPython notebook is by default hidden for easier reading.\n",
       "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
